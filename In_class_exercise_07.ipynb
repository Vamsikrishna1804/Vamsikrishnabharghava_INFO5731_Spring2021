{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In_class_exercise_07.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vamsikrishna1804/Vamsikrishnabharghava_INFO5731_Spring2021/blob/main/In_class_exercise_07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9SytPcnMHRk"
      },
      "source": [
        "# **The seventh in-class-exercise (20 points in total, 3/16/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPvgtqqaMHRn"
      },
      "source": [
        "Question description: In the last in-class-exercise (exercise-06), you collected the titles of 100 articles about data science, natural language processing, and machine learning. The 100 article titles will be used as the text corpus of this exercise. Perform the following tasks:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XPhmfl5MHRp"
      },
      "source": [
        "## (1) (8 points) Generate K topics by using LDA, the number of topics K should be decided by the coherence score, then summarize what are the topics. You may refer the code here: \n",
        "\n",
        "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaEQCaN3MHRp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c11a0287-5500-4acb-bd89-f422e0833e26"
      },
      "source": [
        "# Write your code here\n",
        "import re\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "\n",
        "# Gensim\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# spacy for lemmatization\n",
        "import spacy\n",
        "\n",
        "# Plotting tools\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim  # don't skip this\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Enable logging for gensim - optional\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Iterable\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wdkUE7gQizS",
        "outputId": "9913edaa-0947-4d3b-d660-d92e630bbed3"
      },
      "source": [
        "!pip install pyLDAvis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyLDAvis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/38/6d81eff34c84c9158d3b7c846bff978ac88b0c2665548941946d3d591158/pyLDAvis-3.2.2.tar.gz (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.36.2)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.8.4 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.1)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.7.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Collecting funcy\n",
            "  Downloading https://files.pythonhosted.org/packages/66/89/479de0afbbfb98d1c4b887936808764627300208bb771fcd823403645a36/funcy-1.15-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.0->pyLDAvis) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.0->pyLDAvis) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.17.0->pyLDAvis) (1.15.0)\n",
            "Building wheels for collected packages: pyLDAvis\n",
            "  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-3.2.2-py2.py3-none-any.whl size=135593 sha256=409d59f735f487f9560380fd8fc92d58865d086b4aac4d2932baaa8af275240b\n",
            "  Stored in directory: /root/.cache/pip/wheels/74/df/b6/97234c8446a43be05c9a8687ee0db1f1b5ade5f27729187eae\n",
            "Successfully built pyLDAvis\n",
            "Installing collected packages: funcy, pyLDAvis\n",
            "Successfully installed funcy-1.15 pyLDAvis-3.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1CswESiRPCH",
        "outputId": "e7a8bff0-963e-436b-b25f-bafbd8642e67"
      },
      "source": [
        "import nltk; nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dus_h-evQc5T"
      },
      "source": [
        "# NLTK Stop words\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "8yHGowAURW4i",
        "outputId": "61c47043-347d-43f3-e796-e1cc1cb35508"
      },
      "source": [
        "df = pd.read_csv('titles.csv')\n",
        "df.head(100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Journal Data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A general framework for causal classification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Introduction to the special issue on social mi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Linking bank clients using graph neural networ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>A survey on training and evaluation of word em...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Using network features for credit scoring in m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>Correction to: A clinical risk matrix for obst...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>Introduction to the special issue on social da...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>Accurate classification of socially generated ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>Multi-domain and multi-view networks model for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>A clinical risk matrix for obstructive sleep a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed: 0                                       Journal Data\n",
              "0            0      A general framework for causal classification\n",
              "1            1  Introduction to the special issue on social mi...\n",
              "2            2  Linking bank clients using graph neural networ...\n",
              "3            3  A survey on training and evaluation of word em...\n",
              "4            4  Using network features for credit scoring in m...\n",
              "..         ...                                                ...\n",
              "95          95  Correction to: A clinical risk matrix for obst...\n",
              "96          96  Introduction to the special issue on social da...\n",
              "97          97  Accurate classification of socially generated ...\n",
              "98          98  Multi-domain and multi-view networks model for...\n",
              "99          99  A clinical risk matrix for obstructive sleep a...\n",
              "\n",
              "[100 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2BhRiYlSB_o",
        "outputId": "ce0956ef-8bd0-43aa-b700-9f5b2d381774"
      },
      "source": [
        "# Convert to list\n",
        "data = df['Journal Data'].tolist()\n",
        "\n",
        "# Remove Emails\n",
        "data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
        "\n",
        "# Remove new line characters\n",
        "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
        "\n",
        "# Remove distracting single quotes\n",
        "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
        "\n",
        "pprint(data[:1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['A general framework for causal classification']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MqOjLKWSOrN",
        "outputId": "36f00b4a-1951-4610-949f-78065e2e6054"
      },
      "source": [
        "def sentence_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "\n",
        "data_words = list(sentence_to_words(data))\n",
        "\n",
        "print(data_words[:1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['general', 'framework', 'for', 'causal', 'classification']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6Z8NAJfSa_v",
        "outputId": "15137957-9884-48a8-9d95-fd39bca5ce65"
      },
      "source": [
        "# Build the bigram and trigram models\n",
        "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
        "\n",
        "# Faster way to get a sentence clubbed as a trigram/bigram\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "\n",
        "# See trigram example\n",
        "print(trigram_mod[bigram_mod[data_words[0]]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['general', 'framework', 'for', 'causal', 'classification']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBsnvJbBSjiu"
      },
      "source": [
        "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "def make_bigrams(texts):\n",
        "    return [bigram_mod[doc] for doc in texts]\n",
        "\n",
        "def make_trigrams(texts):\n",
        "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faGbc_U9SufL",
        "outputId": "f6f0240b-6fd9-4737-c433-30d6af7151ef"
      },
      "source": [
        "# Remove Stop Words\n",
        "data_words_nostops = remove_stopwords(data_words)\n",
        "\n",
        "# Form Bigrams\n",
        "data_words_bigrams = make_bigrams(data_words_nostops)\n",
        "\n",
        "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
        "# python3 -m spacy download en\n",
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "\n",
        "# Do lemmatization keeping only noun, adj, vb, adv\n",
        "Clean_data = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "\n",
        "print(Clean_data[:1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['classification']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKt2roFQTFh9",
        "outputId": "60dbfd90-833c-4ab8-c019-2d3d08b5a9e7"
      },
      "source": [
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(Clean_data)\n",
        "\n",
        "# Create Corpus\n",
        "texts = Clean_data\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "# View\n",
        "print(corpus[:1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[(0, 1)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AwyLM-wmTXQE",
        "outputId": "80196c81-ce31-4fc8-df05-ccbb0086fcd2"
      },
      "source": [
        "id2word[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'classification'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f5PfBacTbIv",
        "outputId": "1a714967-cefb-4fbe-a373-050f0cf9d111"
      },
      "source": [
        "# Human readable format of corpus (term-frequency)\n",
        "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('classification', 1)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U9ZEuQqTecj"
      },
      "source": [
        "# Build LDA model\n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=20, \n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9Y78VPbTiR9",
        "outputId": "4c5cc9cf-4160-4d7a-9fb1-8d1fc44eb088"
      },
      "source": [
        "# Print the Keyword in the 10 topics\n",
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0,\n",
            "  '0.059*\"detection\" + 0.055*\"data\" + 0.046*\"optimization\" + 0.046*\"automatic\" '\n",
            "  '+ 0.036*\"datum\" + 0.031*\"use\" + 0.030*\"ensemble\" + 0.030*\"dynamic\" + '\n",
            "  '0.027*\"outlier\" + 0.023*\"problem\"'),\n",
            " (1,\n",
            "  '0.082*\"challenge\" + 0.051*\"datum\" + 0.038*\"medicine\" + 0.038*\"quality\" + '\n",
            "  '0.034*\"detection\" + 0.034*\"outlier\" + 0.027*\"big\" + 0.027*\"model\" + '\n",
            "  '0.027*\"source\" + 0.027*\"dimension\"'),\n",
            " (2,\n",
            "  '0.055*\"law\" + 0.033*\"multi\" + 0.017*\"eigenanalysis\" + 0.017*\"consistently\" '\n",
            "  '+ 0.017*\"model\" + 0.017*\"basis\" + 0.017*\"orient\" + 0.017*\"department\" + '\n",
            "  '0.017*\"admission\" + 0.017*\"network\"'),\n",
            " (3,\n",
            "  '0.082*\"classification\" + 0.049*\"prescription\" + 0.049*\"forecast\" + '\n",
            "  '0.038*\"study\" + 0.027*\"mining\" + 0.023*\"episode\" + 0.023*\"tract\" + '\n",
            "  '0.023*\"planning\" + 0.023*\"respiratory\" + 0.023*\"causally\"'),\n",
            " (4,\n",
            "  '0.091*\"text\" + 0.038*\"latent\" + 0.038*\"long\" + 0.038*\"short\" + '\n",
            "  '0.038*\"model\" + 0.027*\"autoregression\" + 0.027*\"range\" + 0.027*\"cross\" + '\n",
            "  '0.027*\"forecasting\" + 0.023*\"neural\"'),\n",
            " (5,\n",
            "  '0.080*\"cluster\" + 0.080*\"algorithm\" + 0.067*\"base\" + 0.046*\"tree\" + '\n",
            "  '0.040*\"datum\" + 0.035*\"system\" + 0.027*\"use\" + 0.027*\"efficient\" + '\n",
            "  '0.027*\"mining\" + 0.027*\"structure\"'),\n",
            " (6,\n",
            "  '0.077*\"tree\" + 0.064*\"network\" + 0.051*\"variable\" + 0.039*\"embed\" + '\n",
            "  '0.039*\"aware\" + 0.034*\"use\" + 0.030*\"edge\" + 0.021*\"interpret\" + '\n",
            "  '0.021*\"intree\" + 0.019*\"datum\"'),\n",
            " (7,\n",
            "  '0.045*\"analytic\" + 0.045*\"measure\" + 0.045*\"structure\" + 0.032*\"univariate\" '\n",
            "  '+ 0.032*\"skewness\" + 0.032*\"alternative\" + 0.032*\"way\" + 0.027*\"scoring\" + '\n",
            "  '0.027*\"credit\" + 0.027*\"microfinance\"'),\n",
            " (8,\n",
            "  '0.051*\"model\" + 0.042*\"influence\" + 0.042*\"optimization\" + 0.041*\"revenue\" '\n",
            "  '+ 0.033*\"heuristic\" + 0.030*\"feature\" + 0.023*\"programming\" + '\n",
            "  '0.023*\"maximization\" + 0.019*\"simultaneous\" + 0.019*\"segmentation\"'),\n",
            " (9,\n",
            "  '0.071*\"model\" + 0.048*\"analytic\" + 0.046*\"datum\" + 0.024*\"dynamic\" + '\n",
            "  '0.024*\"heterogeneous\" + 0.024*\"stochastic\" + 0.024*\"compute\" + 0.024*\"real\" '\n",
            "  '+ 0.024*\"analysis\" + 0.017*\"classification\"'),\n",
            " (10,\n",
            "  '0.098*\"stream\" + 0.054*\"prediction\" + 0.043*\"online\" + '\n",
            "  '0.041*\"recommendation\" + 0.041*\"pattern\" + 0.032*\"risk\" + 0.032*\"science\" + '\n",
            "  '0.023*\"negative\" + 0.023*\"characterize\" + 0.023*\"computational\"'),\n",
            " (11,\n",
            "  '0.019*\"tinnitu\" + 0.019*\"ad\" + 0.019*\"mention\" + 0.019*\"direction\" + '\n",
            "  '0.019*\"current\" + 0.019*\"support\" + 0.014*\"statistic\" + 0.010*\"crowd\" + '\n",
            "  '0.010*\"fire\" + 0.010*\"interactive\"'),\n",
            " (12,\n",
            "  '0.053*\"regression\" + 0.045*\"future\" + 0.043*\"use\" + 0.035*\"sleep\" + '\n",
            "  '0.027*\"label\" + 0.027*\"classification\" + 0.027*\"similarity\" + 0.027*\"level\" '\n",
            "  '+ 0.024*\"entity\" + 0.024*\"matrix\"'),\n",
            " (13,\n",
            "  '0.085*\"machine\" + 0.069*\"learning\" + 0.065*\"pattern\" + 0.058*\"base\" + '\n",
            "  '0.043*\"application\" + 0.038*\"spatial\" + 0.025*\"search\" + 0.024*\"system\" + '\n",
            "  '0.019*\"testing\" + 0.019*\"significance\"'),\n",
            " (14,\n",
            "  '0.144*\"datum\" + 0.101*\"science\" + 0.061*\"special\" + 0.061*\"issue\" + '\n",
            "  '0.053*\"big\" + 0.041*\"mining\" + 0.032*\"social\" + 0.027*\"infrastructure\" + '\n",
            "  '0.022*\"statistic\" + 0.015*\"proposal\"'),\n",
            " (15,\n",
            "  '0.082*\"feature\" + 0.065*\"use\" + 0.054*\"identification\" + 0.039*\"batch\" + '\n",
            "  '0.039*\"deep\" + 0.029*\"graph\" + 0.023*\"model\" + 0.023*\"learning\" + '\n",
            "  '0.023*\"content\" + 0.023*\"unsupervise\"'),\n",
            " (16,\n",
            "  '0.093*\"learn\" + 0.032*\"multivariate\" + 0.032*\"task\" + 0.032*\"stream\" + '\n",
            "  '0.032*\"adaptive\" + 0.032*\"hierarchical\" + 0.032*\"multi\" + 0.028*\"model\" + '\n",
            "  '0.028*\"inference\" + 0.023*\"machine\"'),\n",
            " (17,\n",
            "  '0.071*\"approach\" + 0.043*\"base\" + 0.035*\"personalized\" + 0.035*\"training\" + '\n",
            "  '0.035*\"pagerank\" + 0.027*\"selection\" + 0.027*\"population\" + 0.027*\"correct\" '\n",
            "  '+ 0.027*\"identify\" + 0.027*\"improve\"'),\n",
            " (18,\n",
            "  '0.067*\"drive\" + 0.067*\"analyze\" + 0.067*\"social\" + 0.056*\"bias\" + '\n",
            "  '0.048*\"medium\" + 0.048*\"performance\" + 0.028*\"impact\" + 0.028*\"analysis\" + '\n",
            "  '0.020*\"declarative\" + 0.020*\"academic\"'),\n",
            " (19,\n",
            "  '0.079*\"base\" + 0.057*\"framework\" + 0.057*\"scalable\" + 0.057*\"factor\" + '\n",
            "  '0.057*\"mobile\" + 0.055*\"datum\" + 0.043*\"meet\" + 0.033*\"supervise\" + '\n",
            "  '0.033*\"predict\" + 0.025*\"learn\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTIYJUlkT2a1",
        "outputId": "75761b8f-7e1f-41bc-d2ff-be444886831f"
      },
      "source": [
        "# Compute Perplexity\n",
        "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=Clean_data, dictionary=id2word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Perplexity:  -6.8162956953607\n",
            "\n",
            "Coherence Score:  0.3900510933478749\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "id": "56d6R7leUGX4",
        "outputId": "34b6081f-3667-4a08-bba4-deabbfe1c16d"
      },
      "source": [
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
        "vis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el631403158211739689082477464\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el631403158211739689082477464_data = {\"mdsDat\": {\"x\": [0.16738668795463393, -0.21733348579315176, -0.06256226661089537, 0.0004188385344039452, 0.05628355091097079, -0.10273756830401552, 0.07146773920650422, -0.029106798682078047, 0.07883337359788492, 0.05556733605274118, -0.12329426693023773, 0.02008688609537233, 0.06951739230606668, -0.07779866357396421, 0.03625700951546357, 0.03238302502138656, -0.03437852466531361, 0.053532299203262836, -0.005237687910356069, 0.010715124071322387], \"y\": [-0.23861578608701484, -0.15662148406126078, 0.07802905115445435, 0.07823444904598356, 0.13453459857659564, 0.05117352470683244, 0.026325640729460406, 0.03601866460764155, -0.002813324612638008, 0.09008599284140272, -0.01092973835400314, -0.059970089102401876, 0.010306651650212429, 0.0018153985937633603, -0.015026296846865246, 0.0015875042344309748, -0.028046752983472298, 0.030105678885499965, -0.018755101278899067, -0.007438581699723571], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [8.042376384821496, 7.002350306906674, 6.760188624231003, 6.515335353352839, 6.484309941702275, 6.311748084781854, 5.864659317220617, 5.385494028684822, 4.923487124058774, 4.916915413332456, 4.8060752185119, 4.776727568946642, 4.5265183439485694, 4.484718199017863, 4.07325314482582, 3.7411074946374843, 3.677565481537084, 3.215509635867505, 2.489145854827098, 2.0025144787872278]}, \"tinfo\": {\"Term\": [\"datum\", \"base\", \"science\", \"model\", \"stream\", \"feature\", \"tree\", \"learn\", \"classification\", \"use\", \"machine\", \"social\", \"challenge\", \"pattern\", \"cluster\", \"algorithm\", \"learning\", \"detection\", \"text\", \"approach\", \"analytic\", \"network\", \"optimization\", \"special\", \"issue\", \"big\", \"drive\", \"analyze\", \"mining\", \"data\", \"tinnitu\", \"ad\", \"mention\", \"current\", \"direction\", \"support\", \"fire\", \"interactive\", \"rule\", \"visualization\", \"association\", \"crowdsense\", \"platform\", \"prospective\", \"rating\", \"retrospective\", \"stress\", \"variability\", \"classifier\", \"induce\", \"laser\", \"article\", \"evolve\", \"news\", \"story\", \"accidental\", \"advertiser\", \"click\", \"clicked\", \"cost\", \"statistic\", \"crowd\", \"issue\", \"special\", \"science\", \"infrastructure\", \"big\", \"curriculum\", \"proposal\", \"sobigdata\", \"introduction\", \"artistry\", \"dexterous\", \"quant\", \"interaction\", \"ecosystem\", \"open\", \"responsible\", \"better\", \"diagram\", \"teach\", \"language\", \"workflow\", \"mining\", \"research\", \"statistic\", \"datum\", \"social\", \"propertie\", \"basis\", \"consistently\", \"eigenanalysis\", \"era\", \"official\", \"opportunity\", \"threat\", \"real\", \"stochastic\", \"heterogeneous\", \"compute\", \"estate\", \"investment\", \"location\", \"elliptical\", \"perturbation\", \"large\", \"scale\", \"analytic\", \"computer\", \"epidemiological\", \"presence\", \"vaccination\", \"world\", \"business\", \"determine\", \"itemset\", \"placement\", \"retail\", \"high\", \"order\", \"extra\", \"unsupervised\", \"hybrid\", \"movement\", \"railway\", \"robust\", \"model\", \"analysis\", \"dynamic\", \"datum\", \"system\", \"classification\", \"use\", \"revenue\", \"approach\", \"infection\", \"network\", \"query\", \"regression\", \"tree\", \"method\", \"future\", \"sleep\", \"label\", \"level\", \"entity\", \"matrix\", \"regression\", \"augment\", \"estimation\", \"least\", \"likelihood\", \"maximum\", \"predictor\", \"reduction\", \"sufficient\", \"value\", \"apnea\", \"bayesian\", \"clinical\", \"obstructive\", \"similarity\", \"functional\", \"gps\", \"speed\", \"vehicle\", \"observation\", \"refer\", \"traffic\", \"correction\", \"risk\", \"use\", \"classification\", \"network\", \"approach\", \"datum\", \"detection\", \"exploit\", \"analysis\", \"identification\", \"batch\", \"deep\", \"process\", \"spectral\", \"feature\", \"delayed\", \"redundant\", \"removal\", \"inappropriate\", \"unsupervise\", \"content\", \"graph\", \"detect\", \"electrical\", \"energy\", \"facility\", \"manufacturing\", \"pharmaceutical\", \"cumulant\", \"hawke\", \"nonstationary\", \"advertisement\", \"classify\", \"filter\", \"parent\", \"path\", \"propagation\", \"collective\", \"point\", \"selection\", \"use\", \"learning\", \"online\", \"detection\", \"model\", \"profile\", \"segmentation\", \"novel\", \"rank\", \"inference\", \"data\", \"ensemble\", \"automatic\", \"consider\", \"temporal\", \"stable\", \"solve\", \"mix\", \"water\", \"emotion\", \"twitt\", \"infer\", \"jacket\", \"occurrence\", \"problem\", \"example\", \"limited\", \"number\", \"optimization\", \"dynamic\", \"detection\", \"event\", \"concept\", \"hierarchy\", \"mixed\", \"specification\", \"type\", \"iterative\", \"warp\", \"betweenness\", \"outlier\", \"time\", \"use\", \"datum\", \"graph\", \"training\", \"pagerank\", \"personalized\", \"population\", \"correct\", \"twitter\", \"user\", \"cycle\", \"solution\", \"evaluation\", \"survey\", \"optimize\", \"web\", \"identify\", \"improve\", \"approach\", \"novel\", \"rank\", \"embedding\", \"word\", \"document\", \"boost\", \"feasible\", \"subset\", \"covariance\", \"distance\", \"eigenvalue\", \"eigenvector\", \"estimate\", \"mahalanobis\", \"selection\", \"query\", \"base\", \"regression\", \"algorithm\", \"method\", \"variable\", \"embed\", \"aware\", \"edge\", \"interpret\", \"intree\", \"bank\", \"client\", \"link\", \"rich\", \"transactional\", \"tree\", \"power\", \"causal\", \"network\", \"assignment\", \"extension\", \"instrumental\", \"irregular\", \"aircraft\", \"flight\", \"plan\", \"trajectory\", \"neural\", \"semantic\", \"mechanism\", \"node\", \"content\", \"framework\", \"prediction\", \"use\", \"datum\", \"application\", \"spatial\", \"machine\", \"learning\", \"abandon\", \"significance\", \"testing\", \"fluctuate\", \"hyperspectral\", \"image\", \"advertising\", \"coverage\", \"engine\", \"pattern\", \"improved\", \"integration\", \"member\", \"miss\", \"record\", \"search\", \"diverse\", \"recommender\", \"service\", \"system\", \"base\", \"propertie\", \"basis\", \"consistently\", \"eigenanalysis\", \"orient\", \"automate\", \"class\", \"damage\", \"tune\", \"vector\", \"elliptical\", \"perturbation\", \"influence\", \"maximization\", \"programming\", \"revenue\", \"context\", \"dependencie\", \"fusion\", \"heartbeat\", \"simultaneous\", \"heuristic\", \"term\", \"segmentation\", \"exploit\", \"pre\", \"diffusion\", \"influential\", \"resample\", \"optimization\", \"long\", \"simulation\", \"train\", \"top\", \"predictive\", \"interpretable\", \"node\", \"embedding\", \"word\", \"document\", \"feature\", \"identify\", \"model\", \"classification\", \"base\", \"use\", \"challenge\", \"medicine\", \"quality\", \"dimension\", \"source\", \"personalised\", \"precision\", \"strategie\", \"behavior\", \"exercise\", \"lifestyle\", \"subspace\", \"scientist\", \"randomized\", \"analyse\", \"asset\", \"birth\", \"heritage\", \"minor\", \"promise\", \"device\", \"legal\", \"objective\", \"subjective\", \"well\", \"outlier\", \"medical\", \"search\", \"big\", \"research\", \"detection\", \"datum\", \"model\", \"analytic\", \"method\", \"problem\", \"drive\", \"analyze\", \"bias\", \"medium\", \"performance\", \"impact\", \"declarative\", \"academic\", \"discovery\", \"key\", \"student\", \"polar\", \"sentimental\", \"attention\", \"mitigate\", \"social\", \"mechanism\", \"child\", \"occupation\", \"parental\", \"community\", \"joint\", \"overlap\", \"role\", \"analysis\", \"probabilistic\", \"semantic\", \"learn\", \"approach\", \"propertie\", \"interaction\", \"hierarchical\", \"adaptive\", \"task\", \"multivariate\", \"learn\", \"ahead\", \"incremental\", \"step\", \"accuracy\", \"candidate\", \"expansion\", \"trade\", \"inference\", \"multi\", \"merge\", \"reduce\", \"statistical\", \"generic\", \"purpose\", \"transformation\", \"dirichlet\", \"failure\", \"mixture\", \"sparse\", \"accelerate\", \"approximation\", \"time\", \"stream\", \"machine\", \"prediction\", \"model\", \"cluster\", \"algorithm\", \"efficient\", \"computation\", \"dominance\", \"relation\", \"skyline\", \"effective\", \"free\", \"mine\", \"sequential\", \"appraisal\", \"hispeed\", \"structure\", \"representative\", \"near\", \"neighbor\", \"neighborhood\", \"system\", \"tree\", \"base\", \"mining\", \"query\", \"automatic\", \"use\", \"datum\", \"propertie\", \"basis\", \"consistently\", \"eigenanalysis\", \"pattern\", \"sleep\", \"approach\", \"network\", \"recommendation\", \"stream\", \"characterize\", \"computational\", \"negative\", \"sentiment\", \"prediction\", \"perspective\", \"purchase\", \"online\", \"group\", \"risk\", \"sensitive\", \"crowd\", \"sensor\", \"human\", \"contracting\", \"corruption\", \"market\", \"pattern\", \"time\", \"unsupervise\", \"science\", \"outlier\", \"detection\", \"network\", \"propertie\", \"basis\", \"consistently\", \"eigenanalysis\", \"emotion\", \"twitt\", \"delayed\", \"effective\", \"prescription\", \"study\", \"forecast\", \"causally\", \"episode\", \"planning\", \"respiratory\", \"tract\", \"infection\", \"combine\", \"extreme\", \"instance\", \"neighbour\", \"accurate\", \"discourse\", \"generate\", \"socially\", \"behavioral\", \"benchmarke\", \"technique\", \"classification\", \"service\", \"medical\", \"mining\", \"time\", \"feature\", \"propertie\", \"basis\", \"consistently\", \"eigenanalysis\", \"datum\", \"dental\", \"drug\", \"detection\", \"mobile\", \"scalable\", \"factor\", \"meet\", \"supervise\", \"predict\", \"framework\", \"mapreduce\", \"individual\", \"phone\", \"socioeconomic\", \"status\", \"distribute\", \"kriging\", \"spark\", \"fast\", \"base\", \"learn\", \"graph\", \"datum\", \"approach\", \"propertie\", \"basis\", \"consistently\", \"eigenanalysis\", \"orient\", \"admission\", \"department\", \"emergency\", \"hospital\", \"search\", \"subspace\", \"accuracy\", \"candidate\", \"expansion\", \"trade\", \"detection\", \"outlier\", \"time\", \"text\", \"latent\", \"short\", \"autoregression\", \"cross\", \"forecasting\", \"range\", \"long\", \"block\", \"clustering\", \"parallel\", \"slink\", \"hotel\", \"memory\", \"recurrent\", \"reservation\", \"financial\", \"gradient\", \"visualize\", \"neural\", \"term\", \"interpretable\", \"forecast\", \"network\", \"model\", \"base\", \"propertie\", \"basis\", \"consistently\", \"eigenanalysis\", \"inappropriate\", \"detect\", \"datum\", \"cycle\", \"alternative\", \"skewness\", \"univariate\", \"way\", \"measure\", \"credit\", \"microfinance\", \"scoring\", \"structure\", \"discrimination\", \"expose\", \"low\", \"quantitative\", \"safety\", \"sensitivity\", \"probabilistic\", \"correction\", \"traffic\", \"analytic\", \"causal\", \"propertie\", \"basis\", \"consistently\", \"eigenanalysis\", \"orient\", \"admission\", \"department\", \"emergency\", \"hospital\", \"view\", \"datum\", \"use\", \"inference\", \"network\", \"feature\", \"multivariate\", \"approach\", \"classification\", \"big\", \"ecosystem\", \"law\", \"basis\", \"consistently\", \"eigenanalysis\", \"orient\", \"admission\", \"department\", \"emergency\", \"hospital\", \"view\", \"propertie\", \"multi\", \"scheme\", \"group\", \"power\", \"cluster\", \"network\", \"low\", \"quantitative\", \"safety\", \"sensitivity\", \"discrimination\", \"expose\", \"model\", \"representative\", \"near\", \"neighbor\", \"neighborhood\", \"financial\", \"gradient\", \"datum\", \"gap\", \"international\", \"privacy\", \"private\", \"current\", \"direction\", \"classification\", \"big\", \"ecosystem\", \"issue\", \"mining\"], \"Freq\": [27.0, 14.0, 10.0, 14.0, 7.0, 8.0, 8.0, 6.0, 8.0, 15.0, 6.0, 6.0, 5.0, 6.0, 5.0, 5.0, 6.0, 9.0, 3.0, 7.0, 5.0, 7.0, 6.0, 5.0, 5.0, 6.0, 4.0, 4.0, 6.0, 4.0, 1.694135845156116, 1.694112335397928, 1.6941069617389135, 1.6940208152678387, 1.6940208152678387, 1.694017792584643, 0.8602947644249311, 0.8602947644249311, 0.8602947644249311, 0.8602947644249311, 0.8602923294856902, 0.8602923294856902, 0.8602923294856902, 0.8602923294856902, 0.8602923294856902, 0.8602923294856902, 0.8602923294856902, 0.8602923294856902, 0.8602903143635597, 0.8602903143635597, 0.8602903143635597, 0.8602841010703244, 0.8602841010703244, 0.8602841010703244, 0.8602841010703244, 0.8602804066797519, 0.8602804066797519, 0.8602804066797519, 0.8602804066797519, 0.8602804066797519, 1.2821605824253834, 0.8603397688191768, 4.783475585347167, 4.783475585347167, 7.948853374203411, 2.082304486122544, 4.1290446480617184, 1.154016336441868, 1.154016336441868, 1.1539965979787667, 1.1539425730742043, 1.15388935232925, 1.15388935232925, 1.15388935232925, 1.1514414173775969, 0.9637658439426572, 0.9637658439426572, 0.9637658439426572, 0.963765917048076, 0.963765917048076, 0.963765917048076, 0.9637658439426572, 0.9637658439426572, 3.2008432745132693, 0.9637658439426572, 1.7066084278863247, 11.284614453814916, 2.5442250230945236, 0.03547789530188288, 0.03547789530188288, 0.03547789530188288, 0.03547789530188288, 0.035632730294555236, 0.035632730294555236, 0.035632730294555236, 0.035632730294555236, 1.8350411849149826, 1.8350411849149826, 1.8350411849149826, 1.8350411849149826, 1.30851789962738, 1.30851789962738, 1.30851789962738, 1.308430101565159, 1.308430101565159, 1.092979444206264, 1.092979444206264, 3.629617908574589, 0.5666058884918145, 0.5666058884918145, 0.5666058884918145, 0.5666058884918145, 0.5666058884918145, 0.5666058884918145, 0.5666058884918145, 0.5666058884918145, 0.5666058884918145, 0.5666058884918145, 0.5666058884918145, 0.5666058884918145, 0.5666058884918145, 0.5666058884918145, 0.5666058884918145, 0.5666058884918145, 0.5666058884918145, 0.5666058884918145, 5.39850127744368, 1.8350411849149826, 1.835055864976833, 3.479953266464333, 1.092979444206264, 1.308725820118782, 1.215667496504054, 0.6346886629364628, 0.6250967952160106, 0.5666637971011815, 0.5666058884918145, 0.5666058884918145, 0.5666058884918145, 0.5666058884918145, 0.5666058884918145, 3.315072253542616, 2.5210512494438317, 1.9601548123661177, 1.9601545402824319, 1.7297607411741676, 1.729698570051956, 3.8770232869865966, 1.3978035438202847, 1.1674369530806035, 1.1674369530806035, 1.1674369530806035, 1.1674369530806035, 1.1674369530806035, 1.1674369530806035, 1.1674369530806035, 1.1674369530806035, 1.1672858105931263, 1.1672858105931263, 1.1672858105931263, 1.1672858105931263, 1.9601548123661177, 0.6052371671268549, 0.6052371671268549, 0.6052371671268549, 0.6052371671268549, 0.6052371671268549, 0.6052371671268549, 0.6052371671268549, 0.6052371671268549, 1.1672858105931263, 3.161077784870703, 1.9601548123661177, 1.1672858105931263, 1.1672334344836046, 0.7239740794963647, 0.6052371671268549, 0.6052371671268549, 0.6052371671268549, 3.9480572600105184, 2.802596192314144, 2.802595921526095, 1.6571347184356964, 1.6571347184356964, 5.935238065556229, 1.181640923530673, 1.1815785068853761, 1.1815785068853761, 1.1813811023976473, 1.6571347184356964, 1.6571347184356964, 2.132087208030747, 1.181364719720682, 0.5116737184363342, 0.5116737184363342, 0.5116737184363342, 0.5116737184363342, 0.5116737184363342, 0.511673684587828, 0.511673684587828, 0.511673684587828, 0.511673684587828, 0.511673684587828, 0.511673684587828, 0.511673684587828, 0.511673684587828, 0.511673684587828, 0.511673684587828, 0.511673684587828, 1.6570532112329441, 4.691079086604229, 1.6571347184356964, 1.1064904025319588, 1.560540288744786, 1.65718711592318, 0.5116737184363342, 0.511673684587828, 0.511673684587828, 0.511673684587828, 0.511673684587828, 3.919976619010838, 2.1173090711376656, 3.2546231967772847, 1.6453482359407097, 1.6453482359407097, 1.1733875325346435, 1.1733872689528644, 1.1733079308373993, 1.1733079308373993, 1.1729716004874535, 1.1729716004874535, 1.1728810601463826, 1.1728810601463826, 1.1728810601463826, 1.6453482359407097, 0.9799952749752701, 0.9799952749752701, 0.9799952749752701, 3.254750243194741, 2.117296155630497, 4.172917337967023, 1.1732299106308286, 0.5080343738828694, 0.5080343738828694, 0.5080343738828694, 0.5080343738828694, 0.5080343738828694, 0.5080343738828694, 0.5080343738828694, 0.5080343738828694, 1.9239170112646264, 1.0771677289772497, 2.2151781717814214, 2.512678181215177, 0.5080343738828694, 2.2779036961008274, 2.2779036961008274, 2.2779036961008274, 1.7701883579428634, 1.7701883579428634, 1.262295459217938, 1.262295459217938, 1.2621224295068234, 1.0543520750494098, 1.0542961128569261, 1.0542961128569261, 1.0542962353124896, 1.0542962353124896, 1.7701883579428634, 1.7701883579428634, 4.645624629393362, 1.0542962353124896, 1.0542962353124896, 1.0542961128569261, 1.0542961128569261, 1.0542962353124896, 1.262295459217938, 0.5465812645212159, 0.5465812645212159, 0.5465812645212159, 0.5465812645212159, 0.5465812645212159, 0.5465812645212159, 0.5465812645212159, 0.5465812645212159, 1.7702756687595829, 1.0542962353124896, 2.7986726748639694, 0.5468060317078762, 0.5468060317078762, 0.5465812645212159, 3.0644172616966237, 2.331694937025726, 2.3316947121247833, 1.811945933900271, 1.2858085070367062, 1.2858085070367062, 1.0790151260551566, 1.0790151260551566, 1.0790151260551566, 1.0790151260551566, 1.0790151260551566, 4.623464109233665, 1.0790151260551566, 1.079223384328431, 3.8905488195536218, 0.559474774779626, 0.559474774779626, 0.559474774779626, 0.559474774779626, 0.559474774779626, 0.559474774779626, 0.559474774779626, 0.559474774779626, 1.0790151260551566, 0.559474774779626, 0.559474774779626, 0.559474774779626, 0.559474774779626, 0.559474774779626, 0.559474774779626, 2.044704466109589, 1.1731113191718365, 2.360003379043235, 2.1060499872259144, 4.686307721283409, 3.82619809655541, 1.0695113067154478, 1.0695113067154478, 1.0695113067154478, 1.069473474971874, 1.069453428259926, 1.069453428259926, 1.069448082470073, 1.069448082470073, 1.069448082470073, 3.5729540499301002, 0.8931921480359168, 0.8931921480359168, 0.8931921480359168, 0.8931921480359168, 0.8931921480359168, 1.3891031848480992, 0.46305977031722556, 0.46305977031722556, 0.8931921480359168, 1.323372072443203, 3.1820912790502507, 0.032879958351432655, 0.032879958351432655, 0.032879958351432655, 0.032879958351432655, 0.032879958351432655, 0.03301312120563938, 0.03301312120563938, 0.03301312120563938, 0.03301312120563938, 0.03301312120563938, 0.033074241188782515, 0.033074241188782515, 2.3120453802394794, 1.2812054107039952, 1.2812054107039952, 2.2453842712480245, 1.0701549503548902, 1.0701549503548902, 1.0701549503548902, 1.0701549503548902, 1.0701549503548902, 1.7980152936287104, 1.0701549503548902, 1.0701549503548902, 1.0701549503548902, 0.5547736194988118, 0.5547735681655958, 0.5547735681655958, 0.5547735681655958, 2.3119069858890877, 1.0701549503548902, 0.5547735681655958, 0.5547736194988118, 0.5547735681655958, 0.5547735681655958, 0.5547736194988118, 0.5547735681655958, 0.5547736194988118, 0.5547736194988118, 0.5547736194988118, 1.6654297072956956, 0.5547735681655958, 2.826438495353946, 1.0701549503548902, 0.5583691519485409, 0.5553251435717368, 4.427786213778907, 2.0230774765410064, 2.022933772389854, 1.4405439991544284, 1.4405439991544284, 1.027330439623737, 1.027330439623737, 1.027330439623737, 1.0269127743464346, 1.0269127743464346, 1.0269127743464346, 1.026863401132491, 1.0257283189720947, 0.8579651626363414, 0.44479696223715903, 0.44479696223715903, 0.44479696223715903, 0.44479696223715903, 0.44479696223715903, 0.44479696223715903, 0.44479696223715903, 0.44479696223715903, 0.4447969120611286, 0.4447969120611286, 0.4447969120611286, 1.853571606316345, 0.44479696223715903, 0.7185243684373239, 1.4405617614692008, 0.44479696223715903, 1.853571606316345, 2.7668554410939437, 1.4405439991544284, 0.44497985386807776, 0.44479696223715903, 0.44479696223715903, 3.5859464846120663, 3.5859464846120663, 2.977242080577808, 2.5455453660397893, 2.5455451665612405, 1.505144347206787, 1.073400356252633, 1.0732955302750837, 1.0732955302750837, 1.0732955302750837, 1.0732955302750837, 0.8964401426510775, 0.8964401426510775, 0.8964401426510775, 0.8964401426510775, 3.5667075764660834, 0.8964401426510775, 0.46474357772197084, 0.46474357772197084, 0.46474357772197084, 0.46474357772197084, 0.46474357772197084, 0.46474357772197084, 0.46474357772197084, 1.505144347206787, 0.46474357772197084, 0.46474357772197084, 0.46474357772197084, 0.4649346781720035, 0.03299951819706564, 0.03539461661696487, 1.6031607656089488, 1.6031607656089488, 1.6031607656089488, 1.6031607656089488, 4.701600408702363, 1.1431940749357596, 1.1431940749357596, 1.1431940749357596, 0.9546942393051798, 0.9546942393051798, 0.9546942393051798, 0.9546942393051798, 1.4143111305447222, 1.6031607656089488, 0.49500816320062013, 0.49500816320062013, 0.49500816320062013, 0.49500816320062013, 0.49500816320062013, 0.49500816320062013, 0.49500811594319866, 0.49500811594319866, 0.49500811594319866, 0.49500811594319866, 0.49500811594319866, 0.49500811594319866, 0.9546942393051798, 1.6031607656089488, 1.1433198741916861, 0.49500811594319866, 1.4384621302966967, 4.012243261040869, 4.01198106331384, 1.3572729952659854, 0.9679452355315151, 0.9679452355315151, 0.9679452355315151, 0.9679452355315151, 0.9678700409690851, 0.9678700409690851, 0.9678700409690851, 0.9678700409690851, 0.9678415737872934, 0.9678415737872934, 1.3572729952659854, 0.41908532891133765, 0.41908532891133765, 0.41908532891133765, 0.41908532891133765, 1.7465582415118588, 2.2954607552626785, 3.379536547924815, 1.3572729952659854, 0.41908532891133765, 0.41908532891133765, 1.357284045027339, 1.9872235420607391, 0.029757516503216893, 0.029757516503216893, 0.029757516503216893, 0.029757516503216893, 0.038910552375030195, 0.03070299097215283, 0.030010279794174977, 0.02990502906149588, 1.8793625449871887, 4.489054175000874, 1.04141729624045, 1.04141729624045, 1.04141729624045, 1.04141729624045, 2.4700027332526053, 0.8698831766635775, 0.8698369942141576, 1.9457747783652544, 0.8698369942141576, 1.4604771824795741, 0.8698369942141576, 1.0414013917873348, 0.4509517167570945, 0.4509517167570945, 0.45095167423181876, 0.45095167423181876, 0.45095167423181876, 1.8695596184307484, 0.8698369942141576, 0.4509517167570945, 1.4604771824795741, 0.4509517167570945, 0.5587250964216336, 0.45095167423181876, 0.032020214325335715, 0.032020214325335715, 0.032020214325335715, 0.032020214325335715, 0.032266316069352936, 0.032266316069352936, 0.0321541529968407, 0.0320896394957604, 2.0680006020516157, 1.607070066655723, 2.067796252514193, 0.9571454242534545, 0.9571454242534545, 0.9571454242534545, 0.9571454242534545, 0.9571454242534545, 0.9571454242534545, 0.4962152013186281, 0.4962152013186281, 0.4962152013186281, 0.4962152013186281, 0.4962152013186281, 0.4962152013186281, 0.4962152013186281, 0.4962152013186281, 0.4962151622609948, 0.4962151622609948, 0.4962151622609948, 3.450893445624806, 0.9571454242534545, 0.4962152013186281, 1.1461399218361632, 0.40125273705704384, 0.5302063955993851, 0.035234188813899975, 0.035234188813899975, 0.035234188813899975, 0.035234188813899975, 0.041264550693620596, 0.03539977853247721, 0.03539977853247721, 0.035351264069715116, 2.329885750247464, 2.329885750247464, 2.329885750247464, 1.7723139031207347, 1.377628111772126, 1.377628111772126, 2.329885750247464, 0.9818917002573139, 0.42537039650829483, 0.42537039650829483, 0.42537039650829483, 0.42537039650829483, 0.42537035811404816, 0.42537035811404816, 0.42537035811404816, 0.42537035811404816, 3.257013432807574, 1.0147597862258002, 0.42537039650829483, 2.2631110907262393, 0.44307920527087064, 0.030203789209207903, 0.030203789209207903, 0.030203789209207903, 0.030203789209207903, 0.030203789209207903, 0.030203789209207903, 0.030203789209207903, 0.030203789209207903, 0.030203789209207903, 0.03190993834541596, 0.03065035029272474, 0.03035289806547792, 0.03035289806547792, 0.03035289806547792, 0.03035289806547792, 0.030381854526397332, 0.030381854526397332, 0.03035289806547792, 3.2645156845927867, 1.370228963809905, 1.3702288295286031, 0.9770798324142783, 0.9770798324142783, 0.9770798324142783, 0.9770798324142783, 1.3702288295286031, 0.4230857376997662, 0.4230857376997662, 0.4230857376997662, 0.4230857376997662, 0.4230857376997662, 0.4230857376997662, 0.4230857376997662, 0.4230857376997662, 0.42308570412944074, 0.42308570412944074, 0.42308570412944074, 0.816129793976659, 0.4230857376997662, 0.42308570412944074, 0.4230857376997662, 0.816129793976659, 1.3702288295286031, 0.4839017728989855, 0.030041566024879618, 0.030041566024879618, 0.030041566024879618, 0.030041566024879618, 0.03031234007386309, 0.03030693944775244, 0.030225258649583253, 0.03013612314101347, 0.8903218681021984, 0.8903218681021984, 0.8903218681021984, 0.8903065877484674, 1.2484981411638363, 0.7435856187293785, 0.7435856187293785, 0.7435856187293785, 1.2484979332678672, 0.3854988708694468, 0.3854988708694468, 0.3854988448824506, 0.3854988448824506, 0.3854988448824506, 0.3854988448824506, 0.3854988708694468, 0.3854988708694468, 0.3854988448824506, 1.2484981411638363, 0.3854988708694468, 0.0273726779977474, 0.0273726779977474, 0.0273726779977474, 0.0273726779977474, 0.0273726779977474, 0.0273726779977474, 0.0273726779977474, 0.0273726779977474, 0.0273726779977474, 0.0273726779977474, 0.3854988448824506, 0.027879070349677116, 0.027561977022762984, 0.027557383821195037, 0.02750439958443778, 0.027372687742870955, 0.027372681246121917, 0.0273726779977474, 0.0273726779977474, 0.0273726779977474, 1.233303648004663, 0.38080731640006643, 0.38080731640006643, 0.38080731640006643, 0.38080731640006643, 0.38080731640006643, 0.38080731640006643, 0.38080731640006643, 0.38080731640006643, 0.38080731640006643, 0.3808072745870598, 0.7345750813156225, 0.3808072745870598, 0.3808072745870598, 0.3808072745870598, 0.38080731640006643, 0.38080731640006643, 0.027039551484510232, 0.027039551484510232, 0.027039551484510232, 0.027039551484510232, 0.027039551484510232, 0.027039551484510232, 0.38080731640006643, 0.027039551484510232, 0.027039551484510232, 0.027039551484510232, 0.027039551484510232, 0.027039551484510232, 0.027039551484510232, 0.3808072745870598, 0.02705570437162385, 0.02705570437162385, 0.02705570437162385, 0.02705570437162385, 0.027055508373155394, 0.027055508373155394, 0.027039551484510232, 0.027039551484510232, 0.027039551484510232, 0.027039551484510232, 0.027039551484510232], \"Total\": [27.0, 14.0, 10.0, 14.0, 7.0, 8.0, 8.0, 6.0, 8.0, 15.0, 6.0, 6.0, 5.0, 6.0, 5.0, 5.0, 6.0, 9.0, 3.0, 7.0, 5.0, 7.0, 6.0, 5.0, 5.0, 6.0, 4.0, 4.0, 6.0, 4.0, 2.3474637928852036, 2.3474712611572754, 2.347473538239827, 2.3474953367441014, 2.3474953367441014, 2.347501954359023, 1.5136103185105179, 1.5136103185105179, 1.5136103185105179, 1.5136103185105179, 1.5136060617449443, 1.5136060617449443, 1.5136060617449443, 1.5136060617449443, 1.5136060617449443, 1.5136060617449443, 1.5136060617449443, 1.5136060617449443, 1.513609094604717, 1.513609094604717, 1.513609094604717, 1.5136092818406572, 1.5136092818406572, 1.5136092818406572, 1.5136092818406572, 1.5136099106161536, 1.5136099106161536, 1.5136099106161536, 1.5136099106161536, 1.5136099106161536, 3.6066539062515086, 2.523140949134679, 5.427882683382447, 5.427882683382447, 10.021740078953835, 2.726631744696383, 6.182451173719474, 1.7982868942702863, 1.7982868942702863, 1.7982849369379688, 1.7982835273149227, 1.7982597184950133, 1.7982597184950133, 1.7982597184950133, 1.7981070736259144, 1.6080871156668124, 1.6080871156668124, 1.6080871156668124, 1.6080887708184592, 1.6080887708184592, 1.6080887708184592, 1.608093102516496, 1.608093102516496, 6.283535046750575, 2.0213068752953167, 3.6066539062515086, 27.31107003197923, 6.742668724572307, 1.03351617623285, 1.0335162180458566, 1.0335162180458566, 1.0335162180458566, 1.5136438646379042, 1.5136438646379042, 1.5136438646379042, 1.5136438646379042, 2.474557300856842, 2.474557304065168, 2.4745573054259307, 2.474557315314897, 1.9481692615065307, 1.9481692615065307, 1.9481692615065307, 1.9481405003443684, 1.9481405003443684, 1.7324955601481236, 1.7324955601481236, 5.903656156661363, 1.2061220044336733, 1.2061220044336733, 1.2061220044336733, 1.2061220044336733, 1.2061220044336733, 1.2061220044336733, 1.2061220044336733, 1.2061220044336733, 1.2061220044336733, 1.2061220044336733, 1.2061220044336733, 1.2061220044336733, 1.2061220044336733, 1.2061220044336733, 1.2061220044336733, 1.2061220044336733, 1.2061220044336733, 1.2061220044336733, 14.952148494085025, 4.508963912638911, 4.555794730532736, 27.31107003197923, 4.739894853969134, 8.311886869172172, 15.65625691898809, 3.4802491697169886, 7.840805641194331, 2.128091148482595, 7.740482037212865, 2.610992760092354, 5.548208711347788, 8.05572033260819, 2.1271065686070068, 3.951845330682977, 3.158769798941417, 2.596927885260378, 2.5969276116820836, 2.366533809949962, 2.3665148795051065, 5.548208711347788, 2.034659246122268, 1.8042532625337544, 1.8042532625337544, 1.8042532625337544, 1.8042532625337544, 1.8042532625337544, 1.8042532625337544, 1.8042532625337544, 1.8042532625337544, 1.8042063919272002, 1.8042063919272002, 1.8042063919272002, 1.8042063919272002, 3.123301436563751, 1.2420102359026493, 1.2420102359026493, 1.2420102359026493, 1.2420102359026493, 1.2420102359026493, 1.2420102359026493, 1.6001364027873524, 1.6001364287743485, 3.232663360081439, 15.65625691898809, 8.311886869172172, 7.740482037212865, 7.840805641194331, 27.31107003197923, 9.25205106246899, 2.2727730099062162, 4.508963912638911, 4.591473902153033, 3.4460128300395714, 3.4460125474917165, 2.3005513444013177, 2.3005513444013177, 8.699841615345463, 1.8251914881677997, 1.8252234696872702, 1.8252234696872702, 1.8251500982575808, 2.7194828468330763, 2.8203001331680615, 3.6430571480738156, 2.6590173430868695, 1.1550903444019553, 1.1550903444019553, 1.1550903444019553, 1.1550903444019553, 1.1550903444019553, 1.1550903105534491, 1.1550903105534491, 1.1550903105534491, 1.1550903105534491, 1.1550903105534491, 1.1550903105534491, 1.1550903105534491, 1.1550903105534491, 1.1550903105534491, 1.1550903105534491, 1.1550903105534491, 4.031935032831444, 15.65625691898809, 6.0947110017809605, 3.6636615987903536, 9.25205106246899, 14.952148494085025, 1.7173521271743046, 2.1858530845570163, 2.1706332538040085, 2.1706332538040085, 2.534591174111382, 4.563651659633039, 2.760984112650089, 4.287626047183751, 2.2890232739390557, 2.28902327715167, 1.81706257053299, 1.8170623069512108, 1.8170629951663548, 1.8170629951663548, 1.8170127680270822, 1.8170127680270822, 1.8171564123167914, 1.8171564123167914, 1.8171564123167914, 2.702237046717877, 1.6236703129736165, 1.6236703129736165, 1.6236703129736165, 6.170992386672816, 4.555794730532736, 9.25205106246899, 2.651027119070894, 1.1517094118812155, 1.1517094118812155, 1.1517094118812155, 1.1517094118812155, 1.1517094118812155, 1.1517094118812155, 1.1517094118812155, 1.1517094118812155, 4.808690033869927, 3.8444680935702302, 15.65625691898809, 27.31107003197923, 3.6430571480738156, 2.918892271263688, 2.9188988571691974, 2.9188988571691974, 2.41112634060429, 2.4111263431941743, 1.9033277448164023, 1.9033277448164023, 1.9033110858092077, 1.695290055053007, 1.695284684883785, 1.695284684883785, 1.69529139638086, 1.69529139638086, 2.926507735994438, 2.9374998956750615, 7.840805641194331, 2.1706332538040085, 2.1706332538040085, 2.210666128031274, 2.210666128031274, 2.210672839528349, 2.737190256017504, 1.1875192445248126, 1.1875192445248126, 1.1875192445248126, 1.1875192445248126, 1.1875192445248126, 1.1875192445248126, 1.1875192445248126, 1.1875192445248126, 4.031935032831444, 2.610992760092354, 14.138524137096457, 5.548208711347788, 5.17013476359024, 2.1271065686070068, 3.704439736759244, 2.9717174041431447, 2.971717179242202, 2.4519684036415463, 1.9316322855549515, 1.9316322855549515, 1.7192281729552563, 1.7192281729552563, 1.7192281729552563, 1.7192281729552563, 1.7192281729552563, 8.05572033260819, 2.072995896057806, 2.077372044317549, 7.740482037212865, 1.1994972418970444, 1.1994972418970444, 1.1994972418970444, 1.1994972418970444, 1.1994972418970444, 1.1994972418970444, 1.1994972418970444, 1.1994972418970444, 2.5053164009070357, 1.6312413014219498, 2.0629855769567746, 2.190220491134466, 2.8203001331680615, 3.4991792029353004, 4.097339410548369, 15.65625691898809, 27.31107003197923, 3.006922465845365, 2.7530221575206486, 6.442476393302321, 6.0947110017809605, 1.716379801494316, 1.716379801494316, 1.716379801494316, 1.7163835003547887, 1.7163874743475822, 1.7163874743475822, 1.7163841650540839, 1.7163841650540839, 1.7163841650540839, 6.066514989097269, 1.5401112348380468, 1.5401112348380468, 1.5401112348380468, 1.5401112348380468, 1.5401112348380468, 2.72466156105045, 1.1099282650960935, 1.1099282650960935, 2.4620803832980447, 4.739894853969134, 14.138524137096457, 1.03351617623285, 1.0335162180458566, 1.0335162180458566, 1.0335162180458566, 1.0335162180458566, 1.5136331977025932, 1.5136331977025932, 1.5136331977025932, 1.5136331977025932, 1.5136331977025932, 1.9481405003443684, 1.9481405003443684, 2.952453952960422, 1.9216907726265962, 1.9216907726265962, 3.4802491697169886, 1.7105112271338678, 1.7105112271338678, 1.7105112271338678, 1.7105112271338678, 1.7105112271338678, 2.925371772391562, 2.1035553988087545, 2.1858530845570163, 2.2727730099062162, 1.1951298962777892, 1.1951298449445733, 1.1951298449445733, 1.1951298449445733, 6.170992386672816, 3.050698490637591, 1.6670907378000432, 1.7215034475811624, 1.7215033962479462, 1.7215033962479462, 2.1145475856857234, 2.190220491134466, 2.210666128031274, 2.210666128031274, 2.210672839528349, 8.699841615345463, 2.926507735994438, 14.952148494085025, 8.311886869172172, 14.138524137096457, 15.65625691898809, 5.075951480074726, 2.6712427402129686, 2.671243812137417, 2.088709262826391, 2.088709265110935, 1.6754957032956996, 1.6754957032956996, 1.6754957032956996, 1.675507329788626, 1.675507329788626, 1.675507329788626, 1.6754752258879704, 1.6758476602724366, 1.50617390059375, 1.0929622259091214, 1.0929622259091214, 1.0929622259091214, 1.0929622259091214, 1.0929622259091214, 1.0929622259091214, 1.0929622259091214, 1.09296223047821, 1.092962175733091, 1.092962175733091, 1.092962175733091, 4.808690033869927, 1.5539432384138496, 2.72466156105045, 6.182451173719474, 2.0213068752953167, 9.25205106246899, 27.31107003197923, 14.952148494085025, 5.903656156661363, 2.1271065686070068, 2.702237046717877, 4.232695424793014, 4.232695426287623, 3.624039454600205, 3.1922943035968814, 3.1922941014944755, 2.1518932844245664, 1.720149291185868, 1.72015365169724, 1.72015365169724, 1.72015365169724, 1.72015365169724, 1.543236849833549, 1.5432368528014069, 1.5432372696501568, 1.5432376217607597, 6.742668724572307, 2.0629855769567746, 1.1114925126552058, 1.1114925126552058, 1.1114925126552058, 1.1114925126552058, 1.1114925126552058, 1.1114925126552058, 1.1114925126552058, 4.508963912638911, 1.469618705526905, 1.6312413014219498, 6.7625004471315195, 7.840805641194331, 1.03351617623285, 1.7981070736259144, 2.2477607430413293, 2.2477607430413293, 2.2477607458894027, 2.2477607503868122, 6.7625004471315195, 1.7878995142043834, 1.7878995142043834, 1.7878995142043834, 1.5994433231941898, 1.5994433231941898, 1.5994433231941898, 1.5994433231941898, 2.534591174111382, 2.955296270472801, 1.1396081382333603, 1.1396081382333603, 1.1396081382333603, 1.1396081382333603, 1.1396081382333603, 1.1396081382333603, 1.1396080909759387, 1.1396080909759387, 1.1396080909759387, 1.1396080909759387, 1.1396080909759387, 1.6659816422793114, 3.8444680935702302, 7.26705649060768, 6.442476393302321, 4.097339410548369, 14.952148494085025, 5.016076298871549, 5.17013476359024, 2.007263931893069, 1.617936172158599, 1.617936172158599, 1.617936172158599, 1.617936172158599, 1.6179434725210216, 1.6179434725210216, 1.6179434725210216, 1.6179434725210216, 1.617943834525894, 1.617943834525894, 3.228389187163189, 1.0690762655384214, 1.0690762655384214, 1.0690762655384214, 1.0690762655384214, 4.739894853969134, 8.05572033260819, 14.138524137096457, 6.283535046750575, 2.610992760092354, 4.287626047183751, 15.65625691898809, 27.31107003197923, 1.03351617623285, 1.0335162180458566, 1.0335162180458566, 1.0335162180458566, 6.066514989097269, 3.158769798941417, 7.840805641194331, 7.740482037212865, 2.5271336188728246, 7.26705649060768, 1.6892722567151557, 1.6892722567151557, 1.6892722567151557, 1.6892722567151557, 4.097339410548369, 1.5176114154685425, 1.5176080654759365, 3.6636615987903536, 1.871375788578486, 3.232663360081439, 1.992949922899085, 2.523140949134679, 1.0986799555620592, 1.0986799555620592, 1.0986799130367835, 1.0986799130367835, 1.0986799130367835, 6.066514989097269, 3.8444680935702302, 2.7194828468330763, 10.021740078953835, 4.808690033869927, 9.25205106246899, 7.740482037212865, 1.03351617623285, 1.0335162180458566, 1.0335162180458566, 1.0335162180458566, 1.8170127680270822, 1.8170127680270822, 1.8251914881677997, 1.6179434725210216, 2.7125727793884598, 2.2515843394342503, 3.105645609304215, 1.6017119845118204, 1.6017176015902983, 1.6017176015902983, 1.6017176015902983, 1.6017176015902983, 2.128091148482595, 1.1407294656350289, 1.1407294656350289, 1.1407294656350289, 1.1407294656350289, 1.1407294656350289, 1.1407294656350289, 1.1407294656350289, 1.1407294656350289, 1.1407294265773955, 1.1407294265773955, 1.1407294265773955, 8.311886869172172, 2.4620803832980447, 1.5539432384138496, 6.283535046750575, 3.8444680935702302, 8.699841615345463, 1.03351617623285, 1.0335162180458566, 1.0335162180458566, 1.0335162180458566, 27.31107003197923, 1.5136457192410662, 1.5136457192410662, 9.25205106246899, 2.9794304167924137, 2.9794304179952933, 2.979430420238998, 2.422418227154367, 2.0271727756932187, 2.027172781946073, 3.4991792029353004, 1.6320828455824647, 1.0749150604293876, 1.0749150604293876, 1.0749150604293876, 1.0749150604293876, 1.0749150220351409, 1.0749150220351409, 1.0749150220351409, 1.5502568794582894, 14.138524137096457, 6.7625004471315195, 3.6430571480738156, 27.31107003197923, 7.840805641194331, 1.03351617623285, 1.0335162180458566, 1.0335162180458566, 1.0335162180458566, 1.0335162180458566, 1.0335162180458566, 1.0335162180458566, 1.0335162180458566, 1.0335162180458566, 2.72466156105045, 1.6754752258879704, 1.5994433231941898, 1.5994433231941898, 1.5994433231941898, 1.5994433231941898, 9.25205106246899, 4.808690033869927, 3.8444680935702302, 3.914222580047736, 2.0199358547420623, 2.019935716634024, 1.6268790609170107, 1.6268790609170107, 1.6268790609170107, 1.6268790609170107, 3.050698490637591, 1.0727926248051871, 1.0727926248051871, 1.0727926248051871, 1.0727926248051871, 1.0727926248051871, 1.0727926248051871, 1.0727926248051871, 1.0727926248051871, 1.0727925912348617, 1.0727925912348617, 1.0727925912348617, 2.5053164009070357, 2.1035553988087545, 2.1145475856857234, 3.105645609304215, 7.740482037212865, 14.952148494085025, 14.138524137096457, 1.03351617623285, 1.0335162180458566, 1.0335162180458566, 1.0335162180458566, 1.8251500982575808, 2.6590173430868695, 27.31107003197923, 1.9033110858092077, 1.542759149166696, 1.542759149166696, 1.542759149166696, 1.5427662005002793, 2.31408763889918, 1.3960068533455015, 1.3960068533455015, 1.3960068533455015, 3.228389187163189, 1.0378746460019999, 1.0378746460019999, 1.0378746200150037, 1.0378746200150037, 1.0378746200150037, 1.0378746200150037, 1.469618705526905, 1.6001364287743485, 1.6001364027873524, 5.903656156661363, 2.077372044317549, 1.03351617623285, 1.0335162180458566, 1.0335162180458566, 1.0335162180458566, 1.0335162180458566, 1.0335162180458566, 1.0335162180458566, 1.0335162180458566, 1.0335162180458566, 1.0335162180458566, 27.31107003197923, 15.65625691898809, 2.534591174111382, 7.740482037212865, 8.699841615345463, 2.2477607503868122, 7.840805641194331, 8.311886869172172, 6.182451173719474, 1.6080871156668124, 1.8860125553911624, 1.0335162180458566, 1.0335162180458566, 1.0335162180458566, 1.0335162180458566, 1.0335162180458566, 1.0335162180458566, 1.0335162180458566, 1.0335162180458566, 1.0335162180458566, 1.03351617623285, 2.955296270472801, 1.559889727536223, 1.871375788578486, 2.072995896057806, 5.016076298871549, 7.740482037212865, 1.0378746200150037, 1.0378746200150037, 1.0378746200150037, 1.0378746200150037, 1.0378746460019999, 1.0378746460019999, 14.952148494085025, 1.0690762655384214, 1.0690762655384214, 1.0690762655384214, 1.0690762655384214, 1.0727925912348617, 1.0727925912348617, 27.31107003197923, 1.5136201294819294, 1.5136201294819294, 1.5136201294819294, 1.5136201294819294, 2.3474953367441014, 2.3474953367441014, 8.311886869172172, 6.182451173719474, 1.6080871156668124, 5.427882683382447, 6.283535046750575], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.9744, -3.9744, -3.9744, -3.9744, -3.9744, -3.9744, -4.652, -4.652, -4.652, -4.652, -4.652, -4.652, -4.652, -4.652, -4.652, -4.652, -4.652, -4.652, -4.652, -4.652, -4.652, -4.652, -4.652, -4.652, -4.652, -4.652, -4.652, -4.652, -4.652, -4.652, -4.253, -4.652, -2.7979, -2.7979, -2.29, -3.6296, -2.945, -4.2198, -4.2198, -4.2198, -4.2199, -4.2199, -4.2199, -4.2199, -4.222, -4.4, -4.4, -4.4, -4.4, -4.4, -4.4, -4.4, -4.4, -3.1996, -4.4, -3.8285, -1.9396, -3.4292, -7.7019, -7.7019, -7.7019, -7.7019, -7.6975, -7.6975, -7.6975, -7.6975, -3.7208, -3.7208, -3.7208, -3.7208, -4.059, -4.059, -4.059, -4.059, -4.059, -4.2389, -4.2389, -3.0387, -4.8959, -4.8959, -4.8959, -4.8959, -4.8959, -4.8959, -4.8959, -4.8959, -4.8959, -4.8959, -4.8959, -4.8959, -4.8959, -4.8959, -4.8959, -4.8959, -4.8959, -4.8959, -2.6417, -3.7208, -3.7208, -3.0808, -4.2389, -4.0588, -4.1326, -4.7825, -4.7977, -4.8958, -4.8959, -4.8959, -4.8959, -4.8959, -4.8959, -3.0925, -3.3663, -3.6179, -3.6179, -3.743, -3.743, -2.9359, -3.9561, -4.1362, -4.1362, -4.1362, -4.1362, -4.1362, -4.1362, -4.1362, -4.1362, -4.1363, -4.1363, -4.1363, -4.1363, -3.6179, -4.7931, -4.7931, -4.7931, -4.7931, -4.7931, -4.7931, -4.7931, -4.7931, -4.1363, -3.1401, -3.6179, -4.1363, -4.1363, -4.614, -4.7931, -4.7931, -4.7931, -2.913, -3.2556, -3.2556, -3.7811, -3.7811, -2.5053, -4.1193, -4.1193, -4.1193, -4.1195, -3.7811, -3.7811, -3.5291, -4.1195, -4.9563, -4.9563, -4.9563, -4.9563, -4.9563, -4.9563, -4.9563, -4.9563, -4.9563, -4.9563, -4.9563, -4.9563, -4.9563, -4.9563, -4.9563, -4.9563, -3.7812, -2.7405, -3.7811, -4.185, -3.8412, -3.7811, -4.9563, -4.9563, -4.9563, -4.9563, -4.9563, -2.8931, -3.5091, -3.0791, -3.7613, -3.7613, -4.0993, -4.0993, -4.0994, -4.0994, -4.0997, -4.0997, -4.0998, -4.0998, -4.0998, -3.7613, -4.2794, -4.2794, -4.2794, -3.0791, -3.5091, -2.8306, -4.0995, -4.9364, -4.9364, -4.9364, -4.9364, -4.9364, -4.9364, -4.9364, -4.9364, -3.6049, -4.1849, -3.4639, -3.3379, -4.9364, -3.3625, -3.3625, -3.3625, -3.6147, -3.6147, -3.9528, -3.9528, -3.953, -4.1328, -4.1329, -4.1329, -4.1329, -4.1329, -3.6147, -3.6147, -2.6498, -4.1329, -4.1329, -4.1329, -4.1329, -4.1329, -3.9528, -4.7898, -4.7898, -4.7898, -4.7898, -4.7898, -4.7898, -4.7898, -4.7898, -3.6146, -4.1329, -3.1566, -4.7894, -4.7894, -4.7898, -2.9807, -3.2539, -3.2539, -3.5061, -3.8491, -3.8491, -4.0245, -4.0245, -4.0245, -4.0245, -4.0245, -2.5694, -4.0245, -4.0243, -2.742, -4.6813, -4.6813, -4.6813, -4.6813, -4.6813, -4.6813, -4.6813, -4.6813, -4.0245, -4.6813, -4.6813, -4.6813, -4.6813, -4.6813, -4.6813, -3.3853, -3.9409, -3.1522, -3.266, -2.4662, -2.669, -3.9436, -3.9436, -3.9436, -3.9437, -3.9437, -3.9437, -3.9437, -3.9437, -3.9437, -2.7374, -4.1238, -4.1238, -4.1238, -4.1238, -4.1238, -3.6822, -4.7807, -4.7807, -4.1238, -3.7306, -2.8533, -7.4257, -7.4257, -7.4257, -7.4257, -7.4257, -7.4217, -7.4217, -7.4217, -7.4217, -7.4217, -7.4198, -7.4198, -3.1714, -3.7617, -3.7617, -3.2006, -3.9417, -3.9417, -3.9417, -3.9417, -3.9417, -3.4228, -3.9417, -3.9417, -3.9417, -4.5987, -4.5987, -4.5987, -4.5987, -3.1714, -3.9417, -4.5987, -4.5987, -4.5987, -4.5987, -4.5987, -4.5987, -4.5987, -4.5987, -4.5987, -3.4994, -4.5987, -2.9705, -3.9417, -4.5922, -4.5977, -2.4988, -3.2821, -3.2821, -3.6217, -3.6217, -3.9597, -3.9597, -3.9597, -3.9601, -3.9601, -3.9601, -3.9602, -3.9613, -4.1399, -4.7968, -4.7968, -4.7968, -4.7968, -4.7968, -4.7968, -4.7968, -4.7968, -4.7968, -4.7968, -4.7968, -3.3696, -4.7968, -4.3172, -3.6217, -4.7968, -3.3696, -2.969, -3.6217, -4.7964, -4.7968, -4.7968, -2.7035, -2.7035, -2.8896, -3.0462, -3.0462, -3.5717, -3.9097, -3.9098, -3.9098, -3.9098, -3.9098, -4.0899, -4.0899, -4.0899, -4.0899, -2.7089, -4.0899, -4.7468, -4.7468, -4.7468, -4.7468, -4.7468, -4.7468, -4.7468, -3.5717, -4.7468, -4.7468, -4.7468, -4.7464, -7.3918, -7.3218, -3.4548, -3.4548, -3.4548, -3.4548, -2.3789, -3.7929, -3.7929, -3.7929, -3.9731, -3.9731, -3.9731, -3.9731, -3.5801, -3.4548, -4.6299, -4.6299, -4.6299, -4.6299, -4.6299, -4.6299, -4.6299, -4.6299, -4.6299, -4.6299, -4.6299, -4.6299, -3.9731, -3.4548, -3.7928, -4.6299, -3.5632, -2.5281, -2.5282, -3.612, -3.9501, -3.9501, -3.9501, -3.9501, -3.9501, -3.9501, -3.9501, -3.9501, -3.9502, -3.9502, -3.612, -4.7872, -4.7872, -4.7872, -4.7872, -3.3598, -3.0865, -2.6997, -3.612, -4.7872, -4.7872, -3.612, -3.2307, -7.4322, -7.4322, -7.4322, -7.4322, -7.164, -7.4009, -7.4237, -7.4272, -3.1903, -2.3196, -3.7807, -3.7807, -3.7807, -3.7807, -2.917, -3.9606, -3.9607, -3.1556, -3.9607, -3.4425, -3.9607, -3.7807, -4.6176, -4.6176, -4.6176, -4.6176, -4.6176, -3.1955, -3.9607, -4.6176, -3.4425, -4.6176, -4.4033, -4.6176, -7.2626, -7.2626, -7.2626, -7.2626, -7.255, -7.255, -7.2585, -7.2605, -3.0096, -3.2618, -3.0097, -3.78, -3.78, -3.78, -3.78, -3.78, -3.78, -4.4369, -4.4369, -4.4369, -4.4369, -4.4369, -4.4369, -4.4369, -4.4369, -4.4369, -4.4369, -4.4369, -2.4976, -3.78, -4.4369, -3.5998, -4.6494, -4.3707, -7.0819, -7.0819, -7.0819, -7.0819, -6.9239, -7.0772, -7.0772, -7.0786, -2.8732, -2.8732, -2.8732, -3.1468, -3.3987, -3.3987, -2.8732, -3.7373, -4.5739, -4.5739, -4.5739, -4.5739, -4.5739, -4.5739, -4.5739, -4.5739, -2.5382, -3.7044, -4.5739, -2.9023, -4.5331, -7.2188, -7.2188, -7.2188, -7.2188, -7.2188, -7.2188, -7.2188, -7.2188, -7.2188, -7.1639, -7.2042, -7.2139, -7.2139, -7.2139, -7.2139, -7.213, -7.213, -7.2139, -2.4017, -3.2698, -3.2698, -3.608, -3.608, -3.608, -3.608, -3.2698, -4.445, -4.445, -4.445, -4.445, -4.445, -4.445, -4.445, -4.445, -4.445, -4.445, -4.445, -3.788, -4.445, -4.445, -4.445, -3.788, -3.2698, -4.3107, -7.09, -7.09, -7.09, -7.09, -7.081, -7.0812, -7.0839, -7.0868, -3.4449, -3.4449, -3.4449, -3.4449, -3.1068, -3.625, -3.625, -3.625, -3.1068, -4.282, -4.282, -4.282, -4.282, -4.282, -4.282, -4.282, -4.282, -4.282, -3.1068, -4.282, -6.927, -6.927, -6.927, -6.927, -6.927, -6.927, -6.927, -6.927, -6.927, -6.927, -4.282, -6.9086, -6.9201, -6.9202, -6.9222, -6.927, -6.927, -6.927, -6.927, -6.927, -2.9015, -4.0767, -4.0767, -4.0767, -4.0767, -4.0767, -4.0767, -4.0767, -4.0767, -4.0767, -4.0767, -3.4197, -4.0767, -4.0767, -4.0767, -4.0767, -4.0767, -6.7217, -6.7217, -6.7217, -6.7217, -6.7217, -6.7217, -4.0767, -6.7217, -6.7217, -6.7217, -6.7217, -6.7217, -6.7217, -4.0767, -6.7211, -6.7211, -6.7211, -6.7211, -6.7211, -6.7211, -6.7217, -6.7217, -6.7217, -6.7217, -6.7217], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 2.1943, 2.1943, 2.1943, 2.1942, 2.1942, 2.1942, 1.9555, 1.9555, 1.9555, 1.9555, 1.9555, 1.9555, 1.9555, 1.9555, 1.9555, 1.9555, 1.9555, 1.9555, 1.9555, 1.9555, 1.9555, 1.9555, 1.9555, 1.9555, 1.9555, 1.9555, 1.9555, 1.9555, 1.9555, 1.9555, 1.4862, 1.4445, 2.5325, 2.5325, 2.4272, 2.3893, 2.2553, 2.2153, 2.2153, 2.2153, 2.2153, 2.2152, 2.2152, 2.2152, 2.2132, 2.147, 2.147, 2.147, 2.147, 2.147, 2.147, 2.147, 2.147, 1.9844, 1.9183, 1.9107, 1.7751, 1.6843, -0.7129, -0.7129, -0.7129, -0.7129, -1.0901, -1.0901, -1.0901, -1.0901, 2.3951, 2.3951, 2.3951, 2.3951, 2.2961, 2.2961, 2.2961, 2.2961, 2.2961, 2.2335, 2.2335, 2.2077, 1.9386, 1.9386, 1.9386, 1.9386, 1.9386, 1.9386, 1.9386, 1.9386, 1.9386, 1.9386, 1.9386, 1.9386, 1.9386, 1.9386, 1.9386, 1.9386, 1.9386, 1.9386, 1.6754, 1.7951, 1.7848, 0.6338, 1.227, 0.8455, 0.1385, 0.9924, 0.1649, 1.3709, 0.0796, 1.1663, 0.4126, 0.0396, 1.3713, 2.5553, 2.5055, 2.4497, 2.4497, 2.4176, 2.4175, 2.3726, 2.3556, 2.2957, 2.2957, 2.2957, 2.2957, 2.2957, 2.2957, 2.2957, 2.2957, 2.2956, 2.2956, 2.2956, 2.2956, 2.2651, 2.0121, 2.0121, 2.0121, 2.0121, 2.0121, 2.0121, 1.7588, 1.7588, 1.7124, 1.1311, 1.2863, 0.8392, 0.8263, -0.8993, 0.004, 1.4079, 0.7228, 2.5848, 2.5291, 2.5291, 2.4077, 2.4077, 2.3534, 2.301, 2.3009, 2.3009, 2.3008, 2.2404, 2.204, 2.2001, 1.9245, 1.9215, 1.9215, 1.9215, 1.9215, 1.9215, 1.9215, 1.9215, 1.9215, 1.9215, 1.9215, 1.9215, 1.9215, 1.9215, 1.9215, 1.9215, 1.9215, 1.8466, 1.5306, 1.4335, 1.5385, 0.956, 0.5361, 1.5249, 1.2837, 1.2907, 1.2907, 1.1357, 2.6107, 2.4973, 2.4871, 2.4326, 2.4326, 2.3254, 2.3254, 2.3254, 2.3254, 2.3251, 2.3251, 2.3249, 2.3249, 2.3249, 2.2666, 2.2579, 2.2579, 2.2579, 2.123, 1.9965, 1.9665, 1.9476, 1.9443, 1.9443, 1.9443, 1.9443, 1.9443, 1.9443, 1.9443, 1.9443, 1.8467, 1.4905, 0.8072, 0.3768, 0.7927, 2.5883, 2.5883, 2.5883, 2.5272, 2.5272, 2.4256, 2.4256, 2.4254, 2.3613, 2.3612, 2.3612, 2.3612, 2.3612, 2.3335, 2.3298, 2.3128, 2.1141, 2.1141, 2.0958, 2.0958, 2.0958, 2.0622, 2.0603, 2.0603, 2.0603, 2.0603, 2.0603, 2.0603, 2.0603, 2.0603, 2.0131, 1.9294, 1.2165, 0.5191, 0.5897, 1.4774, 2.7318, 2.6789, 2.6789, 2.619, 2.5145, 2.5145, 2.4556, 2.4556, 2.4556, 2.4556, 2.4556, 2.3662, 2.2685, 2.2666, 2.2335, 2.1588, 2.1588, 2.1588, 2.1588, 2.1588, 2.1588, 2.1588, 2.1588, 2.0791, 1.8514, 1.6166, 1.5567, 1.3039, 1.0882, 0.9304, 0.8858, -0.2262, 2.7689, 2.7433, 2.6929, 2.5456, 2.5381, 2.5381, 2.5381, 2.5381, 2.5381, 2.5381, 2.5381, 2.5381, 2.5381, 2.4818, 2.4663, 2.4663, 2.4663, 2.4663, 2.4663, 2.3375, 2.137, 2.137, 1.9972, 1.7353, 1.5198, -0.4367, -0.4367, -0.4367, -0.4367, -0.4367, -0.8142, -0.8142, -0.8142, -0.8142, -0.8142, -1.0647, -1.0647, 2.768, 2.6071, 2.6071, 2.5743, 2.5435, 2.5435, 2.5435, 2.5435, 2.5435, 2.5258, 2.3367, 2.2983, 2.2593, 2.245, 2.245, 2.245, 2.245, 2.0307, 1.9649, 1.9122, 1.8801, 1.8801, 1.8801, 1.6745, 1.6393, 1.63, 1.63, 1.63, 1.3593, 1.3495, 1.3467, 0.9626, -0.2191, -0.3266, 2.8987, 2.7574, 2.7573, 2.6638, 2.6638, 2.5461, 2.5461, 2.5461, 2.5457, 2.5457, 2.5457, 2.5457, 2.5444, 2.4725, 2.1363, 2.1363, 2.1363, 2.1363, 2.1363, 2.1363, 2.1363, 2.1363, 2.1363, 2.1363, 2.1363, 2.082, 1.7844, 1.7024, 1.5786, 1.5214, 1.4276, 0.7457, 0.6955, 0.45, 1.4704, 1.2311, 2.8756, 2.8756, 2.8448, 2.815, 2.815, 2.684, 2.5698, 2.5697, 2.5697, 2.5697, 2.5697, 2.4982, 2.4982, 2.4982, 2.4982, 2.4046, 2.2079, 2.1694, 2.1694, 2.1694, 2.1694, 2.1694, 2.1694, 2.1694, 1.9442, 1.8901, 1.7858, 0.3638, 0.2162, -0.4028, -0.8865, 2.7573, 2.7573, 2.7573, 2.7573, 2.7317, 2.648, 2.648, 2.648, 2.5792, 2.5792, 2.5792, 2.5792, 2.5118, 2.4836, 2.2614, 2.2614, 2.2614, 2.2614, 2.2614, 2.2614, 2.2614, 2.2614, 2.2614, 2.2614, 2.2614, 1.8816, 1.7022, 1.5838, 1.3662, 0.9817, 0.7539, 2.8812, 2.8509, 2.7132, 2.5908, 2.5908, 2.5908, 2.5908, 2.5907, 2.5907, 2.5907, 2.5907, 2.5907, 2.5907, 2.238, 2.168, 2.168, 2.168, 2.168, 2.1061, 1.849, 1.6733, 1.572, 1.2751, 0.7791, 0.6591, 0.4839, -0.4431, -0.4431, -0.4431, -0.4431, -1.9448, -1.5291, -2.4611, -2.4517, 2.9046, 2.719, 2.717, 2.717, 2.717, 2.717, 2.6946, 2.6442, 2.6441, 2.5679, 2.4346, 2.4062, 2.3717, 2.3158, 2.3102, 2.3102, 2.3102, 2.3102, 2.3102, 2.0236, 1.7146, 1.4039, 1.2747, 0.8339, 0.3938, 0.3579, -0.2736, -0.2736, -0.2736, -0.2736, -0.8302, -0.8302, -0.8382, -0.7196, 3.0145, 2.9486, 2.8791, 2.7709, 2.7709, 2.7709, 2.7709, 2.7709, 2.4868, 2.4534, 2.4534, 2.4534, 2.4534, 2.4534, 2.4534, 2.4534, 2.4534, 2.4534, 2.4534, 2.4534, 2.4067, 2.341, 2.1442, 1.5843, 1.026, 0.488, -0.0929, -0.0929, -0.0929, -0.0929, -3.2093, -0.4698, -0.4698, -2.2815, 3.057, 3.057, 3.057, 2.9904, 2.9166, 2.9166, 2.8962, 2.7948, 2.3759, 2.3759, 2.3759, 2.3759, 2.3759, 2.3759, 2.3759, 2.0097, 1.8348, 1.4062, 1.1553, 0.8124, 0.4296, -0.2298, -0.2298, -0.2298, -0.2298, -0.2298, -0.2298, -0.2298, -0.2298, -0.2298, -1.1443, -0.6983, -0.6616, -0.6616, -0.6616, -0.6616, -2.4158, -1.7614, -1.5386, 3.2557, 3.0491, 3.0491, 2.9273, 2.9273, 2.9273, 2.9273, 2.6368, 2.5067, 2.5067, 2.5067, 2.5067, 2.5067, 2.5067, 2.5067, 2.5067, 2.5067, 2.5067, 2.5067, 2.3156, 1.8334, 1.8282, 1.4438, 1.1875, 1.0473, 0.0624, -0.101, -0.101, -0.101, -0.101, -0.6607, -1.0372, -3.3692, -0.7084, 3.1435, 3.1435, 3.1435, 3.1435, 3.0762, 3.0633, 3.0633, 3.0633, 2.7432, 2.7028, 2.7028, 2.7028, 2.7028, 2.7028, 2.7028, 2.355, 2.2699, 2.2699, 2.1396, 2.0089, 0.0621, 0.0621, 0.0621, 0.0621, 0.0621, 0.0621, 0.0621, 0.0621, 0.0621, 0.0621, -0.5673, -2.6375, -0.8281, -1.9447, -2.0635, -0.7149, -1.9643, -2.0227, -1.7267, -0.38, 3.486, 2.9123, 2.9123, 2.9123, 2.9123, 2.9123, 2.9123, 2.9123, 2.9123, 2.9123, 2.9123, 2.5187, 2.5007, 2.3186, 2.2163, 1.3327, 0.8988, 0.2631, 0.2631, 0.2631, 0.2631, 0.2631, 0.2631, 0.2404, 0.2335, 0.2335, 0.2335, 0.2335, 0.23, 0.23, -0.362, -0.1136, -0.1136, -0.1136, -0.1136, -0.5524, -0.5524, -1.8174, -1.5214, -0.1747, -1.3912, -1.5376]}, \"token.table\": {\"Topic\": [9, 12, 1, 13, 1, 13, 5, 1, 9, 13, 8, 7, 14, 19, 3, 4, 12, 3, 19, 12, 4, 9, 14, 3, 4, 7, 3, 1, 2, 8, 1, 12, 4, 1, 6, 18, 8, 8, 7, 9, 10, 14, 17, 5, 4, 11, 2, 6, 12, 2, 11, 1, 7, 3, 13, 8, 16, 11, 15, 1, 3, 4, 10, 16, 1, 5, 1, 1, 8, 4, 14, 5, 14, 15, 3, 3, 6, 6, 5, 8, 10, 7, 4, 1, 7, 9, 19, 18, 1, 15, 1, 5, 1, 2, 7, 1, 6, 2, 3, 4, 6, 8, 11, 14, 17, 12, 5, 5, 1, 10, 1, 5, 4, 5, 6, 11, 15, 3, 2, 2, 10, 11, 1, 12, 7, 7, 10, 14, 12, 1, 3, 6, 2, 8, 14, 14, 7, 7, 5, 3, 8, 7, 10, 6, 5, 9, 6, 4, 3, 16, 1, 3, 7, 4, 7, 1, 6, 1, 6, 11, 13, 4, 10, 8, 3, 5, 17, 5, 7, 5, 10, 16, 5, 1, 8, 9, 16, 18, 8, 17, 14, 4, 10, 4, 1, 4, 5, 6, 15, 5, 10, 3, 1, 10, 13, 6, 3, 14, 3, 9, 5, 7, 10, 9, 12, 3, 7, 9, 5, 13, 1, 3, 16, 6, 5, 13, 10, 10, 2, 8, 9, 2, 1, 1, 8, 3, 10, 8, 2, 3, 8, 2, 3, 6, 6, 12, 4, 2, 3, 1, 18, 20, 13, 17, 5, 9, 4, 4, 11, 4, 6, 8, 3, 10, 18, 9, 13, 7, 5, 17, 4, 10, 4, 19, 8, 12, 11, 12, 17, 9, 1, 3, 7, 19, 14, 2, 14, 16, 9, 12, 6, 6, 17, 3, 5, 10, 11, 13, 18, 3, 13, 20, 13, 15, 3, 4, 8, 18, 8, 18, 1, 5, 8, 10, 5, 5, 7, 6, 4, 4, 6, 1, 5, 15, 2, 1, 6, 10, 7, 3, 6, 11, 7, 5, 5, 9, 15, 12, 11, 7, 15, 3, 5, 3, 8, 16, 1, 5, 12, 7, 8, 10, 11, 17, 8, 15, 3, 10, 4, 16, 3, 1, 1, 6, 5, 4, 5, 10, 5, 2, 1, 15, 11, 2, 3, 7, 3, 11, 18, 5, 7, 1, 3, 15, 9, 4, 5, 4, 3, 4, 7, 14, 5, 10, 2, 16, 2, 3, 1, 3, 10, 8, 4, 15, 3, 1, 17, 3, 3, 2, 15, 11, 19, 9, 11, 5, 10, 5, 7, 8, 5, 15, 15, 12, 14, 9, 16, 18, 9, 3, 4, 6, 10, 10, 19, 14, 4, 2, 2, 12, 7, 6, 11, 9, 2, 6, 5, 4, 6, 1, 2, 13, 3, 1, 11, 4, 13, 15, 1, 14, 19, 12, 16, 7, 11, 4, 17, 1, 7, 3, 9, 14, 13, 2, 6, 10, 9, 18, 1, 6, 13, 15, 1, 3, 10, 16, 13, 4, 3, 10, 7, 8, 8, 3, 8, 14, 1, 6, 7, 6, 19, 5, 3, 3, 4, 5, 6, 8, 10, 14, 7, 3, 4, 1, 8, 1, 4, 1, 6, 6, 19, 7, 7, 10, 2, 3], \"Freq\": [0.5826216313716691, 0.5813434160450264, 0.6606722068785374, 0.6252175275601117, 0.851980611261679, 0.8897744149112164, 0.8657331732969527, 0.6606722068785374, 0.58262015017395, 0.5593155499261941, 0.8336826172425933, 0.1934185559421629, 0.7736742237686516, 0.6481893175225302, 0.4435608797830193, 0.22178043989150964, 0.4435608797830193, 0.6775462347153499, 0.16938655867883748, 0.9450242923593222, 0.55426031327371, 0.6651318824204271, 0.6180684265180503, 0.12753791456660538, 0.12753791456660538, 0.6376895728330269, 0.6002467101809422, 0.6606724813314625, 0.5560931992832008, 0.8336826172425933, 0.6606738868680011, 0.6479884977289943, 0.4914827885336764, 0.6606620425066057, 0.699687884854253, 0.6146738402523526, 0.6730115550598953, 0.5816563593656427, 0.21218622049303174, 0.21218622049303174, 0.07072874016434391, 0.21218622049303174, 0.21218622049303174, 0.8705713379382718, 0.55426031327371, 0.5968341541819189, 0.6218562172354677, 0.8682745748917589, 0.8278055571916925, 0.6469925742403442, 0.16174814356008604, 0.36533814111078916, 0.36533814111078916, 0.8291035204763911, 0.6252175275601117, 0.481377422371406, 0.6243319708348103, 0.7880295971507423, 0.591970889254129, 0.6606620425066057, 0.12030962592968926, 0.24061925185937852, 0.12030962592968926, 0.3609288777890678, 0.6606725630577376, 0.8657331732969527, 0.6606722068785374, 0.6606722068785374, 0.5816563593656427, 0.55426031327371, 0.7974360359908934, 0.8657331732969527, 0.6180713536219614, 0.591970889254129, 0.8082253692901399, 0.8291035204763911, 0.8682745748917589, 0.8737351091054258, 0.7091443837764129, 0.35457219188820643, 0.5846205415883763, 0.8294878473064465, 0.6249467120537758, 0.6606722068785374, 0.842091616292207, 0.58262015017395, 0.7163288615693546, 0.6146738402523526, 0.3963314060369691, 0.3963314060369691, 0.6606738868680011, 0.8657331732969527, 0.8519718734666089, 0.5560847955830667, 0.52540018678809, 0.6606620425066057, 0.8764910861583239, 0.4027670826196051, 0.10984556798716504, 0.03661518932905501, 0.10984556798716504, 0.03661518932905501, 0.10984556798716504, 0.07323037865811002, 0.07323037865811002, 0.5813448897279152, 0.8705714093187618, 0.5478877183477554, 0.6606565772216464, 0.5846205415883763, 0.37607878060663336, 0.37607878060663336, 0.10808414191059829, 0.21616828382119657, 0.43233656764239314, 0.21616828382119657, 0.10808414191059829, 0.8291035204763911, 0.5560931992832008, 0.6218562172354677, 0.8367291673202062, 0.4787645737956005, 0.8519718734666089, 0.5813434160450264, 0.842091616292207, 0.4523509685012242, 0.4523509685012242, 0.6180713536219614, 0.9450242926930201, 0.6606565772216464, 0.4390013418726019, 0.4390013418726019, 0.6218568572918005, 0.8156711958562335, 0.6180685648070484, 0.49819058874678773, 0.842091616292207, 0.842091616292207, 0.8657331479277035, 0.5133099998810313, 0.6730115041260707, 0.45235234182131245, 0.45235234182131245, 0.5503538651991988, 0.8657331479277035, 0.58262015017395, 0.7243793945921443, 0.8451178646132623, 0.8291035204763911, 0.6243297813591668, 0.6606573866959261, 0.5133024217960888, 0.842091616292207, 0.5542459147867506, 0.5898714292157673, 0.37721228606309776, 0.37721228606309776, 0.6606724813314625, 0.6158885778779706, 0.5968341541819189, 0.6252175275601117, 0.43999114546034845, 0.43999114546034845, 0.8336826172425933, 0.8291035204763911, 0.8657331479277035, 0.6712692420719689, 0.6450543863088244, 0.842091616292207, 0.6896677279063023, 0.2298892426354341, 0.11494462131771704, 0.8657331732969527, 0.660672028837686, 0.8336826172425933, 0.5826203758037134, 0.6439884814958258, 0.6146738402523526, 0.2857813052732898, 0.5715626105465796, 0.6180685648070484, 0.8051463434785908, 0.5846205415883763, 0.7591390221442511, 0.6606677464987682, 0.8051463434785908, 0.5489894664588105, 0.27449473322940526, 0.5343662166109401, 0.8657331732969527, 0.5846205415883763, 0.808225372520016, 0.3418368938394712, 0.6836737876789424, 0.8897744149112164, 0.8682745748917589, 0.8291035204763911, 0.6180684265180503, 0.8291035204763911, 0.5826190268488827, 0.8711799490190548, 0.6834084104412568, 0.3417042052206284, 0.5826190268488827, 0.929414118476984, 0.3404255440050635, 0.680851088010127, 0.6493037498717791, 0.5479001430921608, 0.5593155499261941, 0.6606725630577376, 0.4699046846339433, 0.4699046846339433, 0.5503103603090753, 0.39454094617472035, 0.39454094617472035, 0.6774026053800442, 0.8367291673202062, 0.7335057269432271, 0.8336826172425933, 0.6493037498717791, 0.5561404071357566, 0.660672028837686, 0.6606677464987682, 0.5176968760970483, 0.47291439869664204, 0.47291439869664204, 0.5176968760970483, 0.5560858367496329, 0.5133024217960888, 0.8336826172425933, 0.9211695041434081, 0.8291035204763911, 0.8682745748917589, 0.5503103603090753, 0.5813434160450264, 0.7701407541393751, 0.6218545421500196, 0.5772020563876671, 0.6606725630577376, 0.49506522578544754, 0.5302191637810164, 0.7393714853092354, 0.14787429706184707, 0.3281533774801745, 0.656306754960349, 0.5542459147867506, 0.7701408352713223, 0.5968341541819189, 0.5542459147867506, 0.6158885778779706, 0.5816563593656427, 0.5133024217960888, 0.3277937833151783, 0.3277937833151783, 0.7760990797262467, 0.15521981594524933, 0.842091616292207, 0.8657331479277035, 0.6127139947011181, 0.8451246249583043, 0.5203750854426932, 0.5542459147867506, 0.43213575112293656, 0.4847343632305738, 0.4847343632305738, 0.7487151840946312, 0.939762977561243, 0.8256212645614937, 0.6493037498717791, 0.8519797848284296, 0.4701221907536476, 0.4701221907536476, 0.7163288615693546, 0.6180685648070484, 0.47743825373448023, 0.15914608457816007, 0.15914608457816007, 0.6493037498717791, 0.6479883498816262, 0.5503386523528032, 0.8682745748917589, 0.6712692428484884, 0.33440010323452635, 0.13376004129381053, 0.20064006194071582, 0.06688002064690526, 0.06688002064690526, 0.06688002064690526, 0.8291035204763911, 0.6767510993677908, 0.3383755496838954, 0.8897744120035126, 0.591970889254129, 0.12919092056443457, 0.12919092056443457, 0.5167636822577383, 0.12919092056443457, 0.3991511809198853, 0.3991511809198853, 0.6606724813314625, 0.4565750361882657, 0.4565750361882657, 0.4565750361882657, 0.8657331732969527, 0.460695052122468, 0.460695052122468, 0.6158885778779706, 0.8051463434785908, 0.55426031327371, 0.5503103603090753, 0.6606573866959261, 0.27295097350971886, 0.5459019470194377, 0.6218568572918005, 0.6606573866959261, 0.4861454709422346, 0.3240969806281564, 0.5898690939709945, 0.8291035204763911, 0.415913686661655, 0.415913686661655, 0.685189894500023, 0.8657331732969527, 0.8657331732969527, 0.6593571444542367, 0.3296785722271183, 0.9397630370571268, 0.5968382956954174, 0.685189894500023, 0.6589302042718644, 0.5133099998810313, 0.8657331479277035, 0.8291035204763911, 0.8336826172425933, 0.6243297813591668, 0.6606738868680011, 0.8657331732969527, 0.647988674005457, 0.8294878481974316, 0.4823936226317135, 0.8367291313810175, 0.5968382956954174, 0.4932978623756019, 0.24406081600795784, 0.4881216320159157, 0.5808876138028665, 0.5808876138028665, 0.5542459147867506, 0.737307406163271, 0.8291035204763911, 0.6606677464987682, 0.6606677464987682, 0.7401275185791675, 0.8693568195586039, 0.5822917642669935, 0.5822917642669935, 0.5203750854426932, 0.8657331732969527, 0.5560847955830667, 0.6606738868680011, 0.658931658805062, 0.7487148836480352, 0.5560931992832008, 0.38299608305487176, 0.38299608305487176, 0.8291035204763911, 0.6639339584929663, 0.6146738402523526, 0.460695052122468, 0.460695052122468, 0.6606738868680011, 0.808225374012345, 0.7914104679957755, 0.6493037498717791, 0.5542459147867506, 0.5478781182730122, 0.8051463434785908, 0.18023835295790036, 0.7209534118316014, 0.18023835295790036, 0.6180713536219614, 0.5478781182730122, 0.8367291673202062, 0.494729430855915, 0.6243297813591668, 0.6218568572918005, 0.8291035204763911, 0.6606738868680011, 0.28733574845772303, 0.5746714969154461, 0.5816563593656427, 0.3093424488143447, 0.3093424488143447, 0.8291035204763911, 0.660672028837686, 0.6712692425774782, 0.5772020563876671, 0.6410709567140082, 0.7982645665297594, 0.09978307081621993, 0.5967129493365964, 0.7163288615693546, 0.3670180598923508, 0.3670180598923508, 0.45748728817365114, 0.45748728817365114, 0.496039738665008, 0.496039738665008, 0.6130300888828047, 0.501768754201977, 0.501768754201977, 0.591970889254129, 0.6479886727592852, 0.6180685648070484, 0.40616058142685996, 0.40616058142685996, 0.49506525963429066, 0.5826216313716691, 0.3201740274868242, 0.6403480549736484, 0.5998473732267496, 0.5998473732267496, 0.5846205415883763, 0.6481893175225302, 0.6180713536219614, 0.9497368250783502, 0.556085400850185, 0.4449276870250351, 0.5932369160333801, 0.5898695606804186, 0.5503388607944144, 0.47876457327194755, 0.7264743563855603, 0.9211695041434081, 0.8682745748917589, 0.8693568195586039, 0.8051463434785908, 0.5503387809626583, 0.277265306290319, 0.554530612580638, 0.5593155499261941, 0.8082253729644604, 0.6606724813314625, 0.5968382956954174, 0.1376072968873232, 0.2752145937746464, 0.5504291875492928, 0.6606738868680011, 0.3097519976761872, 0.3097519976761872, 0.5813434160450264, 0.888263417439888, 0.842091616292207, 0.5968455901638408, 0.5542459147867506, 0.4932978638971889, 0.8519694717553888, 0.5898714292157673, 0.21097514413481375, 0.21097514413481375, 0.4219502882696275, 0.8897744137838087, 0.6218562172354677, 0.8737351078791501, 0.47538562595798567, 0.5826216313716691, 0.7664357196476582, 0.6606573866959261, 0.26011400684335845, 0.26011400684335845, 0.26011400684335845, 0.8519833217712187, 0.5808876138028665, 0.5808876138028665, 0.6243297813591668, 0.6252175275601117, 0.6249467222032155, 0.5808875964814784, 0.5808875964814784, 0.685191440496066, 0.8336826172425933, 0.5816563593656427, 0.1241353918348145, 0.6206769591740725, 0.248270783669629, 0.6606620425066057, 0.5503538651991988, 0.5253955881867636, 0.8682745748917589, 0.6481893175225302, 0.7354339455860379, 0.8291035204763911, 0.06387222726188074, 0.1916166817856422, 0.31936113630940366, 0.12774445452376149, 0.12774445452376149, 0.06387222726188074, 0.06387222726188074, 0.5253955881867636, 0.8291035204763911, 0.5542459147867506, 0.6606738868680011, 0.8098390615538777, 0.6606620425066057, 0.8051463434785908, 0.660672028837686, 0.8682745748917589, 0.5503386523528032, 0.6481863549225578, 0.5898690939709945, 0.45235234182131245, 0.45235234182131245, 0.6218545421500196, 0.8291035204763911], \"Term\": [\"abandon\", \"academic\", \"accidental\", \"accuracy\", \"ad\", \"adaptive\", \"advertisement\", \"advertiser\", \"advertising\", \"ahead\", \"aircraft\", \"algorithm\", \"algorithm\", \"alternative\", \"analysis\", \"analysis\", \"analysis\", \"analytic\", \"analytic\", \"analyze\", \"apnea\", \"application\", \"appraisal\", \"approach\", \"approach\", \"approach\", \"approximation\", \"article\", \"artistry\", \"assignment\", \"association\", \"attention\", \"augment\", \"automate\", \"automatic\", \"autoregression\", \"aware\", \"bank\", \"base\", \"base\", \"base\", \"base\", \"base\", \"batch\", \"bayesian\", \"behavior\", \"better\", \"betweenness\", \"bias\", \"big\", \"big\", \"boost\", \"boost\", \"business\", \"candidate\", \"causal\", \"causally\", \"challenge\", \"characterize\", \"class\", \"classification\", \"classification\", \"classification\", \"classification\", \"classifier\", \"classify\", \"click\", \"clicked\", \"client\", \"clinical\", \"cluster\", \"collective\", \"computation\", \"computational\", \"compute\", \"computer\", \"concept\", \"consider\", \"content\", \"content\", \"context\", \"correct\", \"correction\", \"cost\", \"covariance\", \"coverage\", \"credit\", \"cross\", \"crowd\", \"crowd\", \"crowdsense\", \"cumulant\", \"current\", \"curriculum\", \"cycle\", \"damage\", \"data\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"declarative\", \"deep\", \"delayed\", \"dental\", \"dependencie\", \"detect\", \"detect\", \"detection\", \"detection\", \"detection\", \"detection\", \"detection\", \"determine\", \"dexterous\", \"diagram\", \"diffusion\", \"dimension\", \"direction\", \"discovery\", \"distance\", \"document\", \"document\", \"dominance\", \"drive\", \"drug\", \"dynamic\", \"dynamic\", \"ecosystem\", \"edge\", \"effective\", \"efficient\", \"eigenvalue\", \"eigenvector\", \"electrical\", \"elliptical\", \"embed\", \"embedding\", \"embedding\", \"emotion\", \"energy\", \"engine\", \"ensemble\", \"entity\", \"epidemiological\", \"episode\", \"era\", \"estate\", \"estimate\", \"estimation\", \"evaluation\", \"event\", \"event\", \"evolve\", \"example\", \"exercise\", \"expansion\", \"exploit\", \"exploit\", \"extension\", \"extra\", \"facility\", \"factor\", \"fast\", \"feasible\", \"feature\", \"feature\", \"feature\", \"filter\", \"fire\", \"flight\", \"fluctuate\", \"forecast\", \"forecasting\", \"framework\", \"framework\", \"free\", \"functional\", \"fusion\", \"future\", \"gap\", \"gps\", \"graph\", \"graph\", \"group\", \"hawke\", \"heartbeat\", \"heterogeneous\", \"heuristic\", \"heuristic\", \"hierarchical\", \"hierarchy\", \"high\", \"hispeed\", \"hybrid\", \"hyperspectral\", \"identification\", \"identify\", \"identify\", \"image\", \"impact\", \"improve\", \"improve\", \"improved\", \"inappropriate\", \"incremental\", \"induce\", \"infection\", \"infection\", \"infer\", \"inference\", \"inference\", \"influence\", \"influential\", \"infrastructure\", \"instrumental\", \"integration\", \"interaction\", \"interactive\", \"international\", \"interpret\", \"interpretable\", \"interpretable\", \"intree\", \"introduction\", \"investment\", \"irregular\", \"issue\", \"itemset\", \"iterative\", \"jacket\", \"key\", \"label\", \"language\", \"large\", \"laser\", \"latent\", \"law\", \"learn\", \"learn\", \"learning\", \"learning\", \"least\", \"level\", \"lifestyle\", \"likelihood\", \"limited\", \"link\", \"location\", \"long\", \"long\", \"machine\", \"machine\", \"mahalanobis\", \"manufacturing\", \"mapreduce\", \"matrix\", \"maximization\", \"maximum\", \"measure\", \"mechanism\", \"mechanism\", \"medicine\", \"medium\", \"meet\", \"member\", \"mention\", \"method\", \"method\", \"microfinance\", \"mine\", \"mining\", \"mining\", \"mining\", \"miss\", \"mitigate\", \"mix\", \"mixed\", \"mobile\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"movement\", \"multi\", \"multi\", \"multivariate\", \"negative\", \"network\", \"network\", \"network\", \"network\", \"neural\", \"neural\", \"news\", \"node\", \"node\", \"node\", \"nonstationary\", \"novel\", \"novel\", \"number\", \"observation\", \"obstructive\", \"occurrence\", \"official\", \"online\", \"online\", \"open\", \"opportunity\", \"optimization\", \"optimization\", \"optimize\", \"order\", \"outlier\", \"outlier\", \"pagerank\", \"parent\", \"path\", \"pattern\", \"pattern\", \"performance\", \"personalised\", \"personalized\", \"perspective\", \"perturbation\", \"pharmaceutical\", \"placement\", \"plan\", \"planning\", \"platform\", \"point\", \"polar\", \"population\", \"power\", \"pre\", \"precision\", \"predict\", \"prediction\", \"prediction\", \"predictive\", \"predictive\", \"predictor\", \"prescription\", \"presence\", \"privacy\", \"private\", \"problem\", \"process\", \"profile\", \"profile\", \"programming\", \"propagation\", \"proposal\", \"prospective\", \"purchase\", \"quality\", \"quant\", \"query\", \"query\", \"railway\", \"randomized\", \"range\", \"rank\", \"rank\", \"rating\", \"real\", \"recommendation\", \"record\", \"reduction\", \"redundant\", \"refer\", \"regression\", \"regression\", \"regression\", \"relation\", \"removal\", \"resample\", \"research\", \"respiratory\", \"responsible\", \"retail\", \"retrospective\", \"revenue\", \"revenue\", \"rich\", \"risk\", \"risk\", \"robust\", \"rule\", \"scalable\", \"scale\", \"scheme\", \"science\", \"science\", \"scientist\", \"scoring\", \"search\", \"search\", \"segmentation\", \"segmentation\", \"selection\", \"selection\", \"semantic\", \"sensitive\", \"sensitive\", \"sentiment\", \"sentimental\", \"sequential\", \"service\", \"service\", \"short\", \"significance\", \"similarity\", \"similarity\", \"simulation\", \"simulation\", \"simultaneous\", \"skewness\", \"skyline\", \"sleep\", \"sobigdata\", \"social\", \"social\", \"solution\", \"solve\", \"source\", \"spatial\", \"special\", \"specification\", \"spectral\", \"speed\", \"stable\", \"statistic\", \"statistic\", \"step\", \"stochastic\", \"story\", \"strategie\", \"stream\", \"stream\", \"stream\", \"stress\", \"structure\", \"structure\", \"student\", \"study\", \"subset\", \"subspace\", \"sufficient\", \"supervise\", \"support\", \"survey\", \"system\", \"system\", \"system\", \"task\", \"teach\", \"temporal\", \"term\", \"testing\", \"text\", \"threat\", \"time\", \"time\", \"time\", \"tinnitu\", \"top\", \"top\", \"tract\", \"trade\", \"traffic\", \"train\", \"train\", \"training\", \"trajectory\", \"transactional\", \"tree\", \"tree\", \"tree\", \"tune\", \"twitt\", \"twitter\", \"type\", \"univariate\", \"unsupervise\", \"unsupervised\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"user\", \"vaccination\", \"value\", \"variability\", \"variable\", \"vector\", \"vehicle\", \"visualization\", \"warp\", \"water\", \"way\", \"web\", \"word\", \"word\", \"workflow\", \"world\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [12, 15, 10, 13, 16, 1, 18, 7, 14, 9, 2, 19, 17, 6, 11, 4, 20, 5, 8, 3]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el631403158211739689082477464\", ldavis_el631403158211739689082477464_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el631403158211739689082477464\", ldavis_el631403158211739689082477464_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el631403158211739689082477464\", ldavis_el631403158211739689082477464_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster      Freq\n",
              "topic                                               \n",
              "11     0.167387 -0.238616       1        1  8.042376\n",
              "14    -0.217333 -0.156621       2        1  7.002350\n",
              "9     -0.062562  0.078029       3        1  6.760189\n",
              "12     0.000419  0.078234       4        1  6.515335\n",
              "15     0.056284  0.134535       5        1  6.484310\n",
              "0     -0.102738  0.051174       6        1  6.311748\n",
              "17     0.071468  0.026326       7        1  5.864659\n",
              "6     -0.029107  0.036019       8        1  5.385494\n",
              "13     0.078833 -0.002813       9        1  4.923487\n",
              "8      0.055567  0.090086      10        1  4.916915\n",
              "1     -0.123294 -0.010930      11        1  4.806075\n",
              "18     0.020087 -0.059970      12        1  4.776728\n",
              "16     0.069517  0.010307      13        1  4.526518\n",
              "5     -0.077799  0.001815      14        1  4.484718\n",
              "10     0.036257 -0.015026      15        1  4.073253\n",
              "3      0.032383  0.001588      16        1  3.741107\n",
              "19    -0.034379 -0.028047      17        1  3.677565\n",
              "4      0.053532  0.030106      18        1  3.215510\n",
              "7     -0.005238 -0.018755      19        1  2.489146\n",
              "2      0.010715 -0.007439      20        1  2.002514, topic_info=               Term      Freq      Total Category  logprob  loglift\n",
              "2             datum  27.00000  27.000000  Default  30.0000  30.0000\n",
              "66             base  14.00000  14.000000  Default  29.0000  29.0000\n",
              "8           science  10.00000  10.000000  Default  28.0000  28.0000\n",
              "38            model  14.00000  14.000000  Default  27.0000  27.0000\n",
              "136          stream   7.00000   7.000000  Default  26.0000  26.0000\n",
              "..              ...       ...        ...      ...      ...      ...\n",
              "0    classification   0.02704   8.311887  Topic20  -6.7217  -1.8174\n",
              "1               big   0.02704   6.182451  Topic20  -6.7217  -1.5214\n",
              "3         ecosystem   0.02704   1.608087  Topic20  -6.7217  -0.1747\n",
              "4             issue   0.02704   5.427883  Topic20  -6.7217  -1.3912\n",
              "5            mining   0.02704   6.283535  Topic20  -6.7217  -1.5376\n",
              "\n",
              "[749 rows x 6 columns], token_table=      Topic      Freq        Term\n",
              "term                             \n",
              "434       9  0.582622     abandon\n",
              "452      12  0.581343    academic\n",
              "475       1  0.660672  accidental\n",
              "99       13  0.625218    accuracy\n",
              "476       1  0.851981          ad\n",
              "...     ...       ...         ...\n",
              "75        7  0.589869         web\n",
              "25        7  0.452352        word\n",
              "25       10  0.452352        word\n",
              "33        2  0.621855    workflow\n",
              "127       3  0.829104       world\n",
              "\n",
              "[516 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[12, 15, 10, 13, 16, 1, 18, 7, 14, 9, 2, 19, 17, 6, 11, 4, 20, 5, 8, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TawyofAGKRrT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80cb3815-2094-4b9c-cdc3-1744d02057cf"
      },
      "source": [
        "import os     \n",
        "def install_java():\n",
        "  !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null      \n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"     #set environment variable\n",
        "  !java -version       \n",
        "install_java()\n",
        "!wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
        "!unzip mallet-2.0.8.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.10\" 2021-01-19\n",
            "OpenJDK Runtime Environment (build 11.0.10+9-Ubuntu-0ubuntu1.18.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.10+9-Ubuntu-0ubuntu1.18.04, mixed mode, sharing)\n",
            "--2021-03-21 17:21:20--  http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
            "Resolving mallet.cs.umass.edu (mallet.cs.umass.edu)... 128.119.246.70\n",
            "Connecting to mallet.cs.umass.edu (mallet.cs.umass.edu)|128.119.246.70|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16184794 (15M) [application/zip]\n",
            "Saving to: ‘mallet-2.0.8.zip.1’\n",
            "\n",
            "mallet-2.0.8.zip.1  100%[===================>]  15.43M  8.59MB/s    in 1.8s    \n",
            "\n",
            "2021-03-21 17:21:22 (8.59 MB/s) - ‘mallet-2.0.8.zip.1’ saved [16184794/16184794]\n",
            "\n",
            "Archive:  mallet-2.0.8.zip\n",
            "replace mallet-2.0.8/bin/classifier2info? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlC09RwdUZsk"
      },
      "source": [
        "# Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
        "import os\n",
        "mallet_path = '/content/mallet-2.0.8/bin/mallet'\n",
        "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6xEsYf8XQP1"
      },
      "source": [
        "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    for num_topics in range(start, limit, step):\n",
        "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
        "        model_list.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "\n",
        "    return model_list, coherence_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNzcy7EhXVyr"
      },
      "source": [
        "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=Clean_data, start=2, limit=40, step=6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvLxJcWdXYNg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "79991960-5d98-49be-eda0-dfc74fcdcab3"
      },
      "source": [
        "limit=40; start=2; step=6;\n",
        "x = range(start, limit, step)\n",
        "plt.plot(x, coherence_values)\n",
        "plt.xlabel(\"Num Topics\")\n",
        "plt.ylabel(\"Coherence score\")\n",
        "plt.legend((\"coherence_values\"), loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSyLnamnXiJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8d4b0d7-6715-4d69-ad7f-612e2288e775"
      },
      "source": [
        "for m, cv in zip(x, coherence_values):\n",
        "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num Topics = 2  has Coherence Value of 0.6549\n",
            "Num Topics = 8  has Coherence Value of 0.7507\n",
            "Num Topics = 14  has Coherence Value of 0.7554\n",
            "Num Topics = 20  has Coherence Value of 0.7521\n",
            "Num Topics = 26  has Coherence Value of 0.7721\n",
            "Num Topics = 32  has Coherence Value of 0.7664\n",
            "Num Topics = 38  has Coherence Value of 0.7679\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnFsf02IXsI1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c5e1a96-c388-46e1-9e36-a0560c033810"
      },
      "source": [
        "optimal_model = model_list[3]\n",
        "model_topics = optimal_model.show_topics(formatted=False)\n",
        "pprint(optimal_model.print_topics(num_words=10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0,\n",
            "  '0.170*\"learning\" + 0.106*\"challenge\" + 0.064*\"ensemble\" + 0.043*\"diagram\" + '\n",
            "  '0.043*\"scalable\" + 0.043*\"sleep\" + 0.043*\"short\" + 0.043*\"member\" + '\n",
            "  '0.043*\"perspective\" + 0.043*\"identify\"'),\n",
            " (1,\n",
            "  '0.179*\"tree\" + 0.071*\"text\" + 0.054*\"interpretable\" + 0.054*\"unsupervise\" + '\n",
            "  '0.054*\"variable\" + 0.054*\"entity\" + 0.036*\"purchase\" + 0.036*\"tract\" + '\n",
            "  '0.036*\"similarity\" + 0.036*\"causal\"'),\n",
            " (2,\n",
            "  '0.120*\"issue\" + 0.100*\"regression\" + 0.060*\"infection\" + 0.040*\"mechanism\" '\n",
            "  '+ 0.040*\"episode\" + 0.040*\"estimation\" + 0.040*\"analysis\" + '\n",
            "  '0.040*\"likelihood\" + 0.040*\"matrix\" + 0.040*\"maximum\"'),\n",
            " (3,\n",
            "  '0.123*\"learn\" + 0.046*\"document\" + 0.046*\"bias\" + 0.046*\"meet\" + '\n",
            "  '0.046*\"inference\" + 0.046*\"influence\" + 0.031*\"accuracy\" + 0.031*\"web\" + '\n",
            "  '0.031*\"optimize\" + 0.031*\"research\"'),\n",
            " (4,\n",
            "  '0.127*\"algorithm\" + 0.127*\"pattern\" + 0.055*\"data\" + 0.036*\"base\" + '\n",
            "  '0.036*\"mobile\" + 0.036*\"infrastructure\" + 0.036*\"miss\" + 0.036*\"sensitive\" '\n",
            "  '+ 0.018*\"mahalanobis\" + 0.018*\"language\"'),\n",
            " (5,\n",
            "  '0.140*\"outlier\" + 0.123*\"optimization\" + 0.105*\"stream\" + 0.088*\"automatic\" '\n",
            "  '+ 0.053*\"revenue\" + 0.035*\"polar\" + 0.035*\"classification\" + '\n",
            "  '0.035*\"analysis\" + 0.035*\"limited\" + 0.018*\"hierarchical\"'),\n",
            " (6,\n",
            "  '0.154*\"social\" + 0.135*\"mining\" + 0.077*\"approach\" + 0.058*\"service\" + '\n",
            "  '0.038*\"scale\" + 0.038*\"clinical\" + 0.038*\"boost\" + 0.019*\"appraisal\" + '\n",
            "  '0.019*\"world\" + 0.019*\"hybrid\"'),\n",
            " (7,\n",
            "  '0.191*\"classification\" + 0.085*\"long\" + 0.064*\"forecast\" + 0.043*\"scoring\" '\n",
            "  '+ 0.043*\"predictive\" + 0.043*\"scheme\" + 0.043*\"feature\" + 0.021*\"diffusion\" '\n",
            "  '+ 0.021*\"current\" + 0.021*\"location\"'),\n",
            " (8,\n",
            "  '0.151*\"model\" + 0.075*\"analyze\" + 0.038*\"mitigate\" + 0.038*\"batch\" + '\n",
            "  '0.038*\"measure\" + 0.038*\"spectral\" + 0.038*\"rich\" + 0.019*\"rating\" + '\n",
            "  '0.019*\"medical\" + 0.019*\"performance\"'),\n",
            " (9,\n",
            "  '0.279*\"base\" + 0.115*\"cluster\" + 0.066*\"selection\" + 0.049*\"aware\" + '\n",
            "  '0.033*\"study\" + 0.033*\"respiratory\" + 0.033*\"improve\" + 0.033*\"node\" + '\n",
            "  '0.033*\"client\" + 0.033*\"tinnitu\"'),\n",
            " (10,\n",
            "  '0.146*\"special\" + 0.098*\"structure\" + 0.073*\"identification\" + '\n",
            "  '0.049*\"profile\" + 0.049*\"teach\" + 0.024*\"retrospective\" + 0.024*\"semantic\" '\n",
            "  '+ 0.024*\"probabilistic\" + 0.024*\"aircraft\" + 0.024*\"language\"'),\n",
            " (11,\n",
            "  '0.183*\"detection\" + 0.117*\"big\" + 0.050*\"embed\" + 0.050*\"medium\" + '\n",
            "  '0.033*\"content\" + 0.033*\"heartbeat\" + 0.033*\"randomized\" + '\n",
            "  '0.033*\"prediction\" + 0.033*\"search\" + 0.017*\"spatial\"'),\n",
            " (12,\n",
            "  '0.224*\"network\" + 0.086*\"graph\" + 0.069*\"multi\" + 0.052*\"embedding\" + '\n",
            "  '0.052*\"neural\" + 0.034*\"large\" + 0.034*\"planning\" + 0.034*\"credit\" + '\n",
            "  '0.034*\"evaluation\" + 0.034*\"recommendation\"'),\n",
            " (13,\n",
            "  '0.240*\"science\" + 0.060*\"training\" + 0.040*\"application\" + 0.040*\"workflow\" '\n",
            "  '+ 0.040*\"pagerank\" + 0.040*\"attention\" + 0.020*\"inference\" + '\n",
            "  '0.020*\"population\" + 0.020*\"tune\" + 0.020*\"analysis\"'),\n",
            " (14,\n",
            "  '0.137*\"time\" + 0.137*\"analytic\" + 0.098*\"system\" + 0.059*\"problem\" + '\n",
            "  '0.059*\"power\" + 0.039*\"candidate\" + 0.039*\"trade\" + 0.020*\"impact\" + '\n",
            "  '0.020*\"movement\" + 0.020*\"stable\"'),\n",
            " (15,\n",
            "  '0.170*\"machine\" + 0.057*\"dynamic\" + 0.038*\"approximation\" + '\n",
            "  '0.038*\"segmentation\" + 0.038*\"term\" + 0.038*\"predictor\" + 0.038*\"reduction\" '\n",
            "  '+ 0.038*\"causally\" + 0.019*\"behavioral\" + 0.019*\"prescription\"'),\n",
            " (16,\n",
            "  '0.225*\"feature\" + 0.050*\"correct\" + 0.050*\"solution\" + 0.050*\"context\" + '\n",
            "  '0.050*\"detect\" + 0.050*\"framework\" + 0.050*\"simultaneous\" + 0.050*\"rank\" + '\n",
            "  '0.025*\"number\" + 0.025*\"exercise\"'),\n",
            " (17,\n",
            "  '0.172*\"model\" + 0.094*\"approach\" + 0.047*\"query\" + 0.047*\"drive\" + '\n",
            "  '0.047*\"group\" + 0.047*\"future\" + 0.031*\"crowd\" + 0.031*\"link\" + 0.031*\"ad\" '\n",
            "  '+ 0.031*\"fusion\"'),\n",
            " (18,\n",
            "  '0.377*\"datum\" + 0.057*\"risk\" + 0.038*\"support\" + 0.038*\"apnea\" + '\n",
            "  '0.038*\"framework\" + 0.019*\"node\" + 0.019*\"car\" + 0.019*\"order\" + '\n",
            "  '0.019*\"skyline\" + 0.019*\"matrix\"'),\n",
            " (19,\n",
            "  '0.279*\"datum\" + 0.059*\"online\" + 0.044*\"statistic\" + 0.044*\"prediction\" + '\n",
            "  '0.044*\"deep\" + 0.029*\"medicine\" + 0.029*\"open\" + 0.029*\"system\" + '\n",
            "  '0.029*\"supervise\" + 0.029*\"dependencie\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2x-8ry8XznA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "71100d9d-8fe2-4826-c389-220d152a1409"
      },
      "source": [
        "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data):\n",
        "    # Init output\n",
        "    sent_topics_df = pd.DataFrame()\n",
        "\n",
        "    # Get main topic in each document\n",
        "    for i, row in enumerate(ldamodel[corpus]):\n",
        "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
        "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
        "        for j, (topic_num, prop_topic) in enumerate(row):\n",
        "            if j == 0:  # => dominant topic\n",
        "                wp = ldamodel.show_topic(topic_num)\n",
        "                topic_keywords = \", \".join([word for word, prop in wp])\n",
        "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
        "            else:\n",
        "                break\n",
        "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
        "\n",
        "    # Add original text to the end of the output\n",
        "    contents = pd.Series(texts)\n",
        "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
        "    return(sent_topics_df)\n",
        "\n",
        "\n",
        "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=data)\n",
        "\n",
        "# Format\n",
        "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
        "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
        "\n",
        "# Show\n",
        "df_dominant_topic.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document_No</th>\n",
              "      <th>Dominant_Topic</th>\n",
              "      <th>Topic_Perc_Contrib</th>\n",
              "      <th>Keywords</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0643</td>\n",
              "      <td>classification, long, forecast, scoring, predi...</td>\n",
              "      <td>A general framework for causal classification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.0993</td>\n",
              "      <td>datum, online, statistic, prediction, deep, me...</td>\n",
              "      <td>Introduction to the special issue on social mi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0861</td>\n",
              "      <td>network, graph, multi, embedding, neural, larg...</td>\n",
              "      <td>Linking bank clients using graph neural networ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0859</td>\n",
              "      <td>network, graph, multi, embedding, neural, larg...</td>\n",
              "      <td>A survey on training and evaluation of word em...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0818</td>\n",
              "      <td>network, graph, multi, embedding, neural, larg...</td>\n",
              "      <td>Using network features for credit scoring in m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0669</td>\n",
              "      <td>algorithm, pattern, data, base, mobile, infras...</td>\n",
              "      <td>A workflow language for research e-infrastruct...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0660</td>\n",
              "      <td>detection, big, embed, medium, content, heartb...</td>\n",
              "      <td>Detection of causally anomalous time-series</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0792</td>\n",
              "      <td>outlier, optimization, stream, automatic, reve...</td>\n",
              "      <td>An influence model for influence maximization–...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0847</td>\n",
              "      <td>feature, correct, solution, context, detect, f...</td>\n",
              "      <td>Exploiting feature fusion and long-term contex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0665</td>\n",
              "      <td>science, training, application, workflow, page...</td>\n",
              "      <td>Mitigating sentimental bias via a polar attent...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Document_No  ...                                               Text\n",
              "0            0  ...      A general framework for causal classification\n",
              "1            1  ...  Introduction to the special issue on social mi...\n",
              "2            2  ...  Linking bank clients using graph neural networ...\n",
              "3            3  ...  A survey on training and evaluation of word em...\n",
              "4            4  ...  Using network features for credit scoring in m...\n",
              "5            5  ...  A workflow language for research e-infrastruct...\n",
              "6            6  ...        Detection of causally anomalous time-series\n",
              "7            7  ...  An influence model for influence maximization–...\n",
              "8            8  ...  Exploiting feature fusion and long-term contex...\n",
              "9            9  ...  Mitigating sentimental bias via a polar attent...\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NthsdKOAX4rG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "9318e660-5bcf-4ce8-b9f8-71d1ec699e06"
      },
      "source": [
        "# Group top 5 sentences under each topic\n",
        "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
        "\n",
        "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
        "\n",
        "for i, grp in sent_topics_outdf_grpd:\n",
        "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
        "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
        "                                            axis=0)\n",
        "\n",
        "# Reset Index    \n",
        "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Format\n",
        "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
        "\n",
        "# Show\n",
        "sent_topics_sorteddf_mallet.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic_Num</th>\n",
              "      <th>Topic_Perc_Contrib</th>\n",
              "      <th>Keywords</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0880</td>\n",
              "      <td>learning, challenge, ensemble, diagram, scalab...</td>\n",
              "      <td>An improved machine learning application for t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.1157</td>\n",
              "      <td>tree, text, interpretable, unsupervise, variab...</td>\n",
              "      <td>Causal tree with instrumental variable: an ext...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.1255</td>\n",
              "      <td>issue, regression, infection, mechanism, episo...</td>\n",
              "      <td>Least squares and maximum likelihood estimatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.1293</td>\n",
              "      <td>learn, document, bias, meet, inference, influe...</td>\n",
              "      <td>When algorithm selection meets Bi-linear Learn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0848</td>\n",
              "      <td>algorithm, pattern, data, base, mobile, infras...</td>\n",
              "      <td>Classifying sensitive content in online advert...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Topic_Num  ...                                               Text\n",
              "0        0.0  ...  An improved machine learning application for t...\n",
              "1        1.0  ...  Causal tree with instrumental variable: an ext...\n",
              "2        2.0  ...  Least squares and maximum likelihood estimatio...\n",
              "3        3.0  ...  When algorithm selection meets Bi-linear Learn...\n",
              "4        4.0  ...  Classifying sensitive content in online advert...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9xlOYSmYCHE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "6e2eb7f1-9660-444f-aee6-1d562bfcee30"
      },
      "source": [
        "# Number of Documents for Each Topic\n",
        "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
        "\n",
        "# Percentage of Documents for Each Topic\n",
        "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
        "\n",
        "# Topic Number and Keywords\n",
        "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
        "\n",
        "# Concatenate Column wise\n",
        "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
        "\n",
        "# Change Column names\n",
        "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
        "\n",
        "# Show\n",
        "df_dominant_topics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dominant_Topic</th>\n",
              "      <th>Topic_Keywords</th>\n",
              "      <th>Num_Documents</th>\n",
              "      <th>Perc_Documents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>classification, long, forecast, scoring, predi...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>19.0</td>\n",
              "      <td>datum, online, statistic, prediction, deep, me...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.0</th>\n",
              "      <td>12.0</td>\n",
              "      <td>network, graph, multi, embedding, neural, larg...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3.0</th>\n",
              "      <td>12.0</td>\n",
              "      <td>network, graph, multi, embedding, neural, larg...</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4.0</th>\n",
              "      <td>12.0</td>\n",
              "      <td>network, graph, multi, embedding, neural, larg...</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155.0</th>\n",
              "      <td>19.0</td>\n",
              "      <td>datum, online, statistic, prediction, deep, me...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156.0</th>\n",
              "      <td>19.0</td>\n",
              "      <td>datum, online, statistic, prediction, deep, me...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157.0</th>\n",
              "      <td>6.0</td>\n",
              "      <td>social, mining, approach, service, scale, clin...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158.0</th>\n",
              "      <td>13.0</td>\n",
              "      <td>science, training, application, workflow, page...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159.0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>learning, challenge, ensemble, diagram, scalab...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>160 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Dominant_Topic  ... Perc_Documents\n",
              "0.0               7.0  ...         0.0625\n",
              "1.0              19.0  ...         0.0562\n",
              "2.0              12.0  ...         0.0625\n",
              "3.0              12.0  ...         0.0812\n",
              "4.0              12.0  ...         0.0688\n",
              "...               ...  ...            ...\n",
              "155.0            19.0  ...            NaN\n",
              "156.0            19.0  ...            NaN\n",
              "157.0             6.0  ...            NaN\n",
              "158.0            13.0  ...            NaN\n",
              "159.0             0.0  ...            NaN\n",
              "\n",
              "[160 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7fhjUIyMHRq"
      },
      "source": [
        "## (2) (8 points) Generate K topics by using LSA, the number of topics K should be decided by the coherence score, then summarize what are the topics. You may refer the code here:\n",
        "\n",
        "https://www.datacamp.com/community/tutorials/discovering-hidden-topics-python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClDe2Zq0MHRq"
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "#import modules\n",
        "import os.path\n",
        "from gensim import corpora\n",
        "from gensim.models import LsiModel\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AR98WxuYUlq"
      },
      "source": [
        "def load_data(path,file_name):\n",
        "    \"\"\"\n",
        "    Input  : path and file_name\n",
        "    Purpose: loading text file\n",
        "    Output : list of paragraphs/documents and\n",
        "             title(initial 100 words considred as title of document)\n",
        "    \"\"\"\n",
        "    documents_list = []\n",
        "    titles=[]\n",
        "    with open( os.path.join(path, file_name) ,\"r\") as fin:\n",
        "        for line in fin.readlines():\n",
        "            text = line.strip()\n",
        "            documents_list.append(text)\n",
        "    print(\"Total Number of Documents:\",len(documents_list))\n",
        "    titles.append( text[0:min(len(text),100)] )\n",
        "    return documents_list,titles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw8d1pOTYrCr"
      },
      "source": [
        "def preprocess_data(doc_set):\n",
        "    \"\"\"\n",
        "    Input  : docuemnt list\n",
        "    Purpose: preprocess text (tokenize, removing stopwords, and stemming)\n",
        "    Output : preprocessed text\n",
        "    \"\"\"\n",
        "    # initialize regex tokenizer\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    # create English stop words list\n",
        "    en_stop = set(stopwords.words('english'))\n",
        "    # Create p_stemmer of class PorterStemmer\n",
        "    p_stemmer = PorterStemmer()\n",
        "    # list for tokenized documents in loop\n",
        "    texts = []\n",
        "    # loop through document list\n",
        "    for i in doc_set:\n",
        "        # clean and tokenize document string\n",
        "        raw = i.lower()\n",
        "        tokens = tokenizer.tokenize(raw)\n",
        "        # remove stop words from tokens\n",
        "        stopped_tokens = [i for i in tokens if not i in en_stop]\n",
        "        # stem tokens\n",
        "        stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
        "        # add tokens to list\n",
        "        texts.append(stemmed_tokens)\n",
        "    return texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNy4M85lZK_W"
      },
      "source": [
        "def prepare_corpus(doc_clean):\n",
        "    \"\"\"\n",
        "    Input  : clean document\n",
        "    Purpose: create term dictionary of our courpus and Converting list of documents (corpus) into Document Term Matrix\n",
        "    Output : term dictionary and Document Term Matrix\n",
        "    \"\"\"\n",
        "    # Creating the term dictionary of our courpus, where every unique term is assigned an index. dictionary = corpora.Dictionary(doc_clean)\n",
        "    dictionary = corpora.Dictionary(doc_clean)\n",
        "    # Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
        "    doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
        "    # generate LDA model\n",
        "    return dictionary,doc_term_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZYzWzf_ZNal"
      },
      "source": [
        "def create_gensim_lsa_model(doc_clean,number_of_topics,words):\n",
        "    \"\"\"\n",
        "    Input  : clean document, number of topics and number of words associated with each topic\n",
        "    Purpose: create LSA model using gensim\n",
        "    Output : return LSA model\n",
        "    \"\"\"\n",
        "    dictionary,doc_term_matrix=prepare_corpus(doc_clean)\n",
        "    # generate LSA model\n",
        "    lsamodel = LsiModel(doc_term_matrix, num_topics=number_of_topics, id2word = dictionary)  # train model\n",
        "    print(lsamodel.print_topics(num_topics=number_of_topics, num_words=words))\n",
        "    return lsamodel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shBeRvZFZQNr"
      },
      "source": [
        "def compute_coherence_values(dictionary, doc_term_matrix, doc_clean, stop, start=2, step=3):\n",
        "    \"\"\"\n",
        "    Input   : dictionary : Gensim dictionary\n",
        "              corpus : Gensim corpus\n",
        "              texts : List of input texts\n",
        "              stop : Max num of topics\n",
        "    purpose : Compute c_v coherence for various number of topics\n",
        "    Output  : model_list : List of LSA topic models\n",
        "              coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
        "    \"\"\"\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    for num_topics in range(start, stop, step):\n",
        "        # generate LSA model\n",
        "        model = LsiModel(doc_term_matrix, num_topics=number_of_topics, id2word = dictionary)  # train model\n",
        "        model_list.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=doc_clean, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "    return model_list, coherence_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlG4FoB3ZSrL"
      },
      "source": [
        "def plot_graph(doc_clean,start, stop, step):\n",
        "    dictionary,doc_term_matrix=prepare_corpus(doc_clean)\n",
        "    model_list, coherence_values = compute_coherence_values(dictionary, doc_term_matrix,doc_clean,\n",
        "                                                            stop, start, step)\n",
        "    # Show graph\n",
        "    x = range(start, stop, step)\n",
        "    plt.plot(x, coherence_values)\n",
        "    plt.xlabel(\"Number of Topics\")\n",
        "    plt.ylabel(\"Coherence score\")\n",
        "    plt.legend((\"coherence_values\"), loc='best')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "eai7EAPyZYQ5",
        "outputId": "d7179dd4-cbac-4617-8733-62cf8bd52a9c"
      },
      "source": [
        "start,stop,step=2,12,1\n",
        "plot_graph(Clean_data,start,stop,step)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3zV9fX48dfJIiQECEmYYWUAskcYJiiKWnGjdYCjtrWiratqHR3fDts6aqtWi6vVWm0lKtqfVEGKiiKgTQIIyE4YSRiBBEggIfOe3x/3Rq8xwA3k5nPvzXk+HveRez/3M06ueE8+73HeoqoYY4wxTYU5HYAxxpjAZAnCGGNMsyxBGGOMaZYlCGOMMc2yBGGMMaZZEU4H0FoSExN1wIABTodhjDFBZcWKFaWqmtTceyGTIAYMGEBeXp7TYRhjTFARkR1He8+amIwxxjTLEoQxxphmWYIwxhjTrJDpg2hOXV0dxcXFVFdXOx3KUUVHR5OcnExkZKTToRhjzNeEdIIoLi4mLi6OAQMGICJOh/MNqkpZWRnFxcUMHDjQ6XCMMeZrQrqJqbq6moSEhIBMDgAiQkJCQkDf4Rhj2q+QThBAwCaHRoEenzGm/Qr5BGGMMf6wtricT7bsczoMv7IEYYwxLbS/spbvvZTD7XNW4XKF7po6liCMMaaFfvOfdZQeruVAVR3rd1c4HY7fWIJoAy+//DIjR45k1KhRXHfddU6HY4w5CYvWl/D257u4emI/AJYXlDockf+E9DBXb7/5zzrW72rdTD+0d2d+ddGwY+6zbt06fve737F8+XISExPZv39/q8ZgjGk75VV1/PzfaxnSM45fXzSMnG37WZZfxqzTU50OzS/sDsLPPvzwQ6644goSExMB6Natm8MRGWNO1APvrKesspY/XjGKqIgwslITyNm2n9p6l9Oh+UW7uYM43l/6xhhzLIs37eXNlcXcemYaw/t0ASAzLZF/fLqDVYUHmJiS4HCErc/uIPxs6tSpvPHGG5SVlQFYE5MxQaiiuo6fvrmWQT06cdtZaV9un5SSQJjAsoIyB6PzH0sQfjZs2DB+/vOfM2XKFEaNGsVdd93ldEjGmBZ68N0N7D1UzaOXj6JDRPiX27t0jGREcleW54dmR3W7aWJy0vXXX8/111/vdBjGmBPwyZZ9ZOcWcdOUFEb17fqN97NSE3h+yVYqa+qJ7RBaX6l2B2GMMUdxuKae+99cS0pSLHeePajZfbLSEql3KTnbQq/52BKEMcYcxcMLNrCr/AiPXj6S6MjwZvcZ1z+eqIgwloZgM1PIJwjVwJ4GH+jxGdNeLS8o5Z+fFfK9zIGM63/04enRkeFk9I9nmSWI4BIdHU1ZWVnAfgk3rgcRHR3tdCjGGC9Vte6mpf4JMdxz7uDj7p+VlsjGPYcoPVzTBtG1ndDqUWkiOTmZ4uJi9u0L3IqLjSvKGWMCx6MLN1G4v4rsWZPoGNV805K3rLREHl24iU8LyrhoVO82iLBt+DVBiMg04M9AOPA3VX34KPt9G5gLjFfVPM+2nwI3AA3A7aq6sKXXj4yMtJXajDEtkrd9Py8t3853Tu3PJB8nv43o04W46AiWF5RagvCFiIQDs4FzgGIgV0Tmqer6JvvFAXcA//PaNhSYAQwDegPvi8ggVW3wV7zGGFNd18C9c9fQp2tH7ps2xOfjwsOESSkJIddR7c8+iAlAvqpuVdVaIBu4pJn9fgs8Anivu3kJkK2qNaq6Dcj3nM8YY/zmsUWb2VpaySPfHtniOQ1ZqQkU7T9C0f4qP0XX9vyZIPoARV6viz3bviQiY4G+qvpuS481xpjWtKrwAH/7ZCszJ/QjKy2xxcc3HhNKo5kcG8UkImHAY8DdJ3GOWSKSJyJ5gdwRbYwJbNV1Ddwzdw09O0fzs/N9b1rylta9E93jOoRUXSZ/JoidQF+v18mebY3igOHARyKyHZgEzBORDB+OBUBVn1fVDFXNSEpKauXwjTHtxZMfbCF/72Ee+vZI4qIjT+gcIkJWWiKfFpQG7ND6lvJngsgF0kVkoIhE4e50ntf4pqqWq2qiqg5Q1QHAZ8DFnlFM84AZItJBRAYC6UCOH2M1xrRTa4vLeW7JVq4Yl8yUQSf3h2ZmagKlh2vZVHKolaJzlt8ShKrWA7cCC4ENwOuquk5EHhCRi49z7DrgdWA98B5wi41gMsa0ttp6F/fMXU1ipyh+ceHQkz5fYz/E0i2h0Q/h13kQqjofmN9k2y+Psu8ZTV7/Hvi934IzxrR7f1mcz8Y9h3jh+gy6dDyxpiVvvbt2ZGBiLMsLyvjBaSmtEKGzQrrUhjHGHM26XeU8vTifS8f04axTerTaeTNTE/jf1jLqGoJ/GVJLEMaYdqeuwcU9b6yha0wUv7ro5JuWvE1OS6SytoE1xQdb9bxOsARhjGl3nv2ogPW7K/jd9OF0jYlq1XOfmpqACCzLD/7hrpYgjDHtyqY9h3jywy1cOLIX04b3bPXzd42JYljvziFRdsMShDGm3ahvcI9a6hwdyW8uHua362SlJrKq8ABVtfV+u0ZbsARhjGk3/vrJNtYUl/ObS4aR0KmD366TmZZIXYOSu/2A367RFixBGGPahfy9h3n8/c1MG9aTC0b08uu1xg+IJzJcWB7kzUyWIIwxIa/BpdwzdzUxUeH8dvpwRMSv14uJimBsv3iWFViCMMaYgPb3ZdtYVXiQX180jKQ4/zUtectKS2TdrgoOVNa2yfX8wRKEMSakbSut5NGFmzj7lO5cMrrtVnvLSktAFT7dGrzDXS1BGGNClsul3Dd3DR0iwvj9pSP83rTkbWRyV2KjwoN6fQhLEMaYkPXyp9vJ2b6f/7twKD06R7fptSPDw5iYksDyIF4fwhKEMSYkFZZV8ch7mzhjcBKXj0t2JIbM1AS2lVay6+ARR65/sixBGGNCjsul3PfmGsLDhAfbuGnJ2+T04F6G1BKEMSbkvJpTyKdby/j5BafQu2tHx+IY3COOxE5RliCMMSYQFB+o4qH5G5iclsiM8X2Pf4AfiQinpiayrKAsKJchtQRhjAkZqspP31qLAg9d5lzTkres1AT2Haohf+9hp0NpMUsQxpiQ8XpeEZ9sKeWn5w2hb7cYp8MBvlqGNBibmSxBGGNCwu7yI/zunQ1MSunGNRP7Ox3Ol/p2i6FftxiWBeFwV0sQxpigp6r87K211LuUR749krAw55uWvGWlJfDZ1jLqg2wZUksQxpig99bKnSzetI97zh1M/4RYp8P5hszURA5V17N2Z7nTobSIJQhjTFDbW1HNb/6zjoz+8Xw3c4DT4TQrMzUBIOhmVVuCMMYELVXl5//vC2rqXfzh8sBrWmqU0KkDQ3rGBV1HtSUIY0zQmrd6F4vWl3D3twaRktTJ6XCOKSstkbwdB6iua3A6FJ9ZgjDGBKV9h2r49bx1jO7blRsmpzgdznFNTkuktt7Fih3BswypJQhjTFD69bx1VNY08OjlIwkP0KYlbxMGdiMiTFgaRM1MliCMMUFnwdrdvLt2N3ecnU56jzinw/FJbIcIRvftGlTrVFuCMMYElf2Vtfzf218wok8Xbjo98JuWvGWmJbJ2ZznlR+qcDsUnliBMQPpx9iomPvg+P3ljNfNW7wrqdX1N69m67zAznv+U8iN1PHrFSCLCg+srLCs1AZfCZ0GyDGmE0wEY01TxgSreXr2LwT3iWLS+hLkrihGBkX26cPqgJE4flMSYvl2D7svBnJxF60u467XPiQgXXvreBIb07Ox0SC02pl88HSPDWZ5fyrnDejodznFZgjAB5/W8YgBe+O54enaOZk3xQZZsLmXJln3MXpzPUx/mE9chgsy0BHfCSE8KmMJspvU1uJQn3t/MUx/mM6JPF565dizJ8cH53zsqIowJA7sFTV0mSxAmoNQ3uHg9t4gpg5Lo41noZUy/eMb0i+eOs9Mpr6pjWUEpSzbvY8nmfSxcVwJASlIsp6cnMWVQEhNTuhETZf+0Q8HBqlruyP6cjzfv48qMZB64ZDjRkeFOh3VSstISeHD+RvaUV9OzS9uuk91S9n+RCSgfb97Hnopqfn3xsGbf7xITyfkjenH+iF6oKgX7DvPxZnfCyM4t5KXl24kKD2P8wHhOT3c3Rw3pGRcQ6wKYllm/q4Kb/pnHnvJqHrx0BDMn9A2J/46Zqe7y38sLSrlsrDNrZfvKEoQJKHNyikjs1IGzTul+3H1FhLTucaR1j+OGyQOprmsgd/t+z91FKQ8t2MhDCzbSPa4Dp6UncfqgRE5LT6JbbFQb/CbmZPx7VTE/fWstXTtG8dpNpzK2X7zTIbWaob06Ex8TybL8svadIERkGvBnIBz4m6o+3OT9m4FbgAbgMDBLVdeLSBTwHJABuIA7VPUjf8ZqnFdSUc3iTXuZdXoKkSfQAR0dGc5p6Umclp7Ezy+APeXVLNnibop6f0MJb660zu5AV9fg4vfvbuCl5duZOLAbf7l6LElxHZwOq1WFhQmnpiawvKAUVQ3ouyK/JQgRCQdmA+cAxUCuiMxT1fVeu72qqs969r8YeAyYBtwIoKojRKQ7sEBExqtqcBVTNy3yRl4RDS5ttXWEe3aJ5sqMvlyZ0ZcGl1pnd4DbW1HNLa+uJHf7AX4weSD3nTfkhP5QCAaZqYnMX7uHbaWVAV1Dyp93EBOAfFXdCiAi2cAlwJcJQlUrvPaPBRpX9R4KfOjZZ6+IHMR9N5Hjx3iNg1wuJTu3iKy0BL/U8w8Pk693dh+pY3l+qecOo/Srzu7EWM/dRSKTUhJ87ux2uZSaehdVtfUcqWuguq6BI7UujtQ1uB+1nm2e51/7WddAtdfzr+3rOU+9y8WFI3txx1mDQu4vaoAVO/bzw3+u5FB1PU/OHMPFo3o7HZJfTW5chrSgLLgThIjEAHcD/VT1RhFJBwar6jvHObQPUOT1uhiY2Mz5bwHuAqKAqZ7Nq4GLRWQO0BcY5/lpCSJELc0vpfjAEe6bNqRNrtelYyTnjejFeV92dle6+y62fL2zO2NAPImdOnh96Tf/pV5d1/Kb2zCBjpHhdIwKJzoy/GvP42Oj6O3ZFh0VTmVNPdk5Rby1cic/OC2FWaen0KlD8HchqiqvfLaDB/6znuT4jrx8Q3DOb2ip/gkx9OnakWVbSrluUuAsj9qUL//C/g6sAE71vN4JvAEcL0H4RFVnA7NF5GrgF8D1wIvAKUAesANYjruf4mtEZBYwC6Bfv36tEY5xSHZuIfExkXxrWI82v7a7s7sTad078f0mnd1L88vYdfCI+ws8yv2F3aVj5JfPG396v9/4pd7xyy/9MDpGRjR5P4yo8LAWtT//+OxBPLpwI09+sIVX/7eD289KZ+aEfkHbDFNd18DP/r2Wt1bu5Kwh3XnsqtF06RjpdFhtQkTITE3gv+tLaHBpwBYb9CVBpKrqVSIyE0BVq8S3f9U7cf/V3yjZs+1osoFnPNeoB+5sfENElgObmx6gqs8DzwNkZGRo0/dNcNh3qIb/rivhu5kD6BDh/Bh3787uQDIwMZanrxnHqsIDPLxgI798ex0vLt3GT84dzAUjegV0Z2dTRfuruOmVFWzYU8GdZw/itqlpAbvYj79kpSXyxopi1u+qYERyF6fDaZYvf3rUikhHPP0DIpIK1PhwXC6QLiIDPaOSZgDzvHfwNFc1ugDY4tkeIyKxnufnAPVNOrdNCHlzZTH1LmXGBLsL9MWYfvFkz5rEi9/NoENEOLe+uorps5fxaZDMzv148z4ufGopxQeqeOH6DO44O73dJQf4ahnSZQWBW93VlzuIXwHvAX1F5F9AFvDd4x2kqvUiciuwEPcw1xdVdZ2IPADkqeo84FYRORuoAw7gbl4C6A4sFBEX7ruO61r2a5lgoaq8llvEhAHdSOseuJ11gUZEmDqkB1MGdeetlcU8tmgzM//6GWcMTuK+aUM4pVfgteO7XMrTH+Xzp0WbGdwjjueuG+eXAQnBonvnaAb16MSy/FJunpLqdDjNOmaCEJEwIB64DJgECO45CT6lPFWdD8xvsu2XXs/vOMpx24HBvlzDBLfPtu5nW2klt01NczqUoBQeJlyR0ZeLRvXmpeXbeXpxPuc/+QmXjUnmrm8N+rJcidMqquu4+/XVLFpfwiWje/PQZSOsHAru4a7ZuYXU1DcERPNqU8dsYvLMO7hXVctU9V1VfcfX5GCML7JzC+kcHcH5I3o5HUpQi44M5+YpqSy590xuPC2F/6zZxZl//IgH52+gvMrZtQe2lBxi+l+W8eHGvfzywqE8cdVoSw4eWWmJVNe5WLnjoNOhNMuXPoj3ReQnItJXRLo1PvwemQl5ByprWfDFHi4d0yfoC7AFiq4xUfzs/FNY/JMzuGhkb/76yVZO+8OHPPdxAdV13xgI6HfvrtnNJbOXUVFdz6s/mMj3Jw8Mqs50f5uY0o0wcddlCkS+JIircJfDWIJ7uOsK3MNPjTkpb63aSW29yzqn/aBP14786cpRzL/9NMb2j+ehBRuZ+sePvpyt7m/1DS4emr+BW15dyeCecbxz22QmpiT4/brBpnN0JCOTu7IsQJchPW6CUNWBzTyCa50/E3BUleycQkb37RqQHaqh4pRenXnpexN49caJJMV14J65a7jgyU9YvHEvqv5JFGWHa/jOizk8t2Qr107qx2uzTg34stZOykpLYHVxOYeqA28Z0uMmCBGJFJHbRWSu53GriLSP2SzGb1YWHmDL3sPMnNA6dZfMsWWmJvL/bsniL1eP4UhdA997KZcZz3/G50Wt2/a9uuggFz21lLwdB3j08pH8bvoIoiKCcyJfW8lKS6TBpeRs2+90KN/gy3+5Z3CXunja8xjn2WbMCZuTU0RsVDgXjgztmjuBRES4cGRvFt05hQcuGUb+3sNMn72MW/61km2llSd9/tdyC7ni2U8REd68OZMrMiz5+2Jsv3g6RISxNACbmXwZSjBeVUd5vf5QRFb7KyAT+iqq63hnzS4uHZNMbAjUEwo2URFhfOfUAVw2Npnnl2zlb59sZeG6Pcyc0I/bz0pvcTHAmvoGfj1vPXNyCpmclsiTM8fYmhstEB0ZzvgB3VieH3gTHX25g2jwzJ4GQERSaKYukjG+envVTqrrXNa85LBOHSK465xBfHTPGcyY0JdXcwo549HFPPH+Zipr6n06x66DR7jyuc+Yk1PIj85I5R/fn2DJ4QRkpiWwqeQQ+w75UqSi7fiSIO4BFovIRyLyMe4y3Hf7NywTqlSVOTlFDOvdmRF9ArP+THvTPS6a300fwaI7T+f0QUk88f4Wpjy6mFc+3U5dw9Gr1C4vKOWip5aSX3KIZ68dy73ThgRs0blAl+W1DGkg8WUU0wdAOnA7cBvuUt+L/R2YCU1rd5azfncFMyb0s/HwASYlqRPPXDuOt36USUpSJ/7v7XV86/ElzF+7+2sjnlSVvy7ZynUv5NA1JpK3b53MtOE20fFkDO/Thc7REQHXzOTLKKZbgI6qukZV1wAxIvIj/4dmQtGcnCI6RoZzyWjrnA5UY/vF89qsSbxwfQaR4cKP/rWS6U8v57OtZVTW1HPrnFX8fv4GzjmlB2/fOtlqaLWCcM8ypEvzS/02/PhE+NJDeKNnzQYAVPWAiNyIe0STMT6rrKln3uc7uWBkLzpH20jpQCYinHVKD84Y3J03Vxbz+KLNzHj+M+JjIik/Usd904Zw85QUuwtsRVlpiSxcV0Lh/qqAKWLoS4IIFxFRT1rzrDVtvVCmxf6zeheVtQ3WOR1EwsOEKzP6crGnGOC7a3bz5MzBAbdWRijI9PRDLMsvC6oE8R7wmog853l9k2ebMS0yJ7eIQT06MbZfvNOhmBZqLAYYqGWpQ0FqUiw9OndgWUEpV08MjPIzvoxiug/3yKUfeh4fAPf6MygTejbsrmB10UFmjLfOaWOaIyJkpSbyaUEZrjaol+ULX0YxuVT1WVW9HPf6z5+qqs2DMC2SnVNIVEQYl43t43QoxgSsrLRE9lfWsnHPIadDAXwbxfSRiHT2lPheAfxVRB73f2gmVBypbeDfq3Zy3vCedI2x7itjjiYrrbEfIjDmQ/jSxNRFVStwryr3sqpOBM7yb1gmlMxfu5uK6npmjA+MdlVjAlXPLtGkJMUGzDrVviSICBHpBVwJvOPneEwIys4tZGBiLJNSbJ0pY44nKzWRnG37qa0/+iz2tuJLgngAWAjkq2qupxbTFv+GZUJF/t5D5G4/wIzxfa1z2hgfZKUlUFXbwOpi55ch9aWT+g1VHamqP/K83qqq3/Z/aCYUZOcUERkufHtcstOhGBMUJqUkIBIY/RC2kofxm5r6Bt5cWcw5Q3uQ2KllJaSNaa+6xkQxok8XSxAmtC1cV8KBqjrrnDamhTJTE1lVeNDnsuv+YgnC+E12TiHJ8R2Z7Bm6Z4zxTVZaAvUuJWe7s8uQ+jIPooeIvCAiCzyvh4rIDf4PzQSzHWWVLC8oY8b4voTZGgHGtEhG/25EhYex3OFmJl/uIF7CPYqpsT7zZuDH/grIhIbs3CLCw8TWJTbmBHSMCmds/64sc3h9CF8SRKKqvg64AFS1Hlty1BxDXYOLN/KKOXNwd3p0jnY6HGOCUlZqIut3V7C/staxGHxJEJUikgA0lvueBJT7NSoT1D7YUELp4Ror623MSchKd34ZUl8SxF3APCBVRJYBL+NeetSYZs3JKaJn52imDLI1A4w5USP7dCGuQ4SjzUzHXQ9CVVeKyBRgMCDAJlWt83tkJigVH6hiyZZ93DY1nYhwGyRnzImKCA9jYkq3wL6D8KxJ3UlV16nqF0AnW5PaHM3recUAXJlhM6eNOVmZqYnsKKui+ECVI9f35U+8G1X1y6IgqnoAuNF/IZlgVd/g4o28Ik5PTyI5PsbpcIwJeo3lv5c71MzkS4IIF68qa7YmtTmajzfvY3d5tXVOG9NKBvXoRGKnDix1aD6ErUltWs2cnCISO3XgrFN6OB2KMSFBRMhKS2BZfhmq2uYVkX1dk3oxJ7AmtYhME5FNIpIvIvc38/7NIrJWRD4XkaUiMtSzPVJE/uF5b4OI/NT3X8k4oaSimsWb9nL5uGQirXPamFaTlZpI6eEaNpccbvNr+zKKyQU843n4zNMUNRs4BygGckVknqqu99rtVVV91rP/xcBjwDTgCqCDqo4QkRhgvYjMUdXtLYnBtJ038opocCkzxlvzkjGtKTMtAXCX/x7cM65Nr+3LKKYsEVkkIptFZKuIbBORrT6cewLuRYa2qmotkA1c4r2DZynTRrF4JuN5fsaKSATQEagFvPc1AcTlUrJzi8hMTWBAYqzT4RgTUpLjY+ifEOPIcFdf+iBeAO4EVtCyEht9gCKv18XAxKY7eYbR3oW743uqZ/Nc3MlkNxAD3Kmq3yhrKCKzgFkA/fpZSWmnLM0vpfjAEe6dNsTpUIwJSZmpifxn9S7qG1xtOr/IlyuVq+oCVd2rqmWNj9YKQFVnq2oq7r6OX3g2T8CdjHoDA4G7PUudNj32eVXNUNWMpCSbteuU7NxC4mMiOXeYdU4b4w+T0xI5XFPP6uK2rXLkS4JYLCKPisipIjK28eHDcTsB7wbpZM+2o8kGpnueXw28p6p1qroXWAZk+HBN08ZKD9ewaH0Jl41NpkNEuNPhGBOSTk1190O0dflvXxLERNxfzg8Cf/I8/ujDcblAuogMFJEoYAbumk5fEpF0r5cXAFs8zwvxNDeJSCwwCdjowzVNG3tzRTF1DWpzH4zxo26xUQzt1ZllbdwP4csopjNP5MSqWi8it+JeSyIceFFV14nIA0Ceqs4DbhWRs4E64ABwvefw2cDfRWQd7vpPf1fVNScSh/EfVXfn9PgB8aR1b9vRFca0N1lpCfxj+Q6O1DbQMapt7taPmyBEpAfuu4feqnqeZ67Cqar6wvGOVdX5wPwm237p9fyOoxx3GPdQVxPAPtu6n22lldx6ZprToRgT8jLTEvnrJ9vI27Gf09Lbps/VVpQzJyw7t5C46AjOH9HL6VCMCXkTBnQjIkzatOyGrShnTsjBqloWfLGHS8f0abPbXWPas9gOEYztF9+mhftsRTlzQt5auZPaehczxtv8E2PaSmZaAl/sKudgVdssQ2orypkWc3dOFzKqb1eG9u7sdDjGtBtZaYmowmdb2+Yu4pgJwlNPaYrnkYm7kuswG1HUvq0sPMDmksPMtLpLxrSpUcldiYkKb7NlSI+ZIFS1AZipqvWNK8rZcqNmTk4RsVHhXDSq9/F3Nsa0mqiIMCYM7NZm8yF8aWJaJiJ/EZHTWjiT2oSgiuo63lmzi4tH9ya2gy+lvIwxrSkrNZGt+yrZXX7E79fy5f/w0Z6fD3htU74qrGfakbc/30V1nXVOG+OUxmVIl+WXcfk4/6797reZ1Cb0qCpz/lfI0F6dGZncxelwjGmXhvSMo1tsFMvzS/2eIHxZD6KHiLwgIgs8r4eKyA1+jcoEpLU7y1m/u4KZE/q2+dKHxhi3sDDh1NQElhWUoqrHP+BkruXDPi9hM6kN7s7p6MgwLhnTx+lQjGnXslITKamooWBfpV+vYzOpjU8qa+qZ9/lOLhjRm87RkU6HY0y7luW1DKk/2Uxq45N31uyisrbBynobEwD6dYuhT9eOfk8QvoxiajqTOgm43K9RmYDzak4R6d07Ma5/vNOhGNPuiQiT0xJZ8MVuGlxKeJh/+gSPewehqiuxmdTt2obdFawuOsiMCf2sc9qYAJGZlkBFdT1f7PRfg46vM50mAAM8+48VEVT1Zb9FZQJKdk4hUeFhXGad08YEjMxUz3yIglJG9e3ql2v4Msz1FdxLjE4Gxnsetj50O1Fd18C/V+1k2vCexMdGOR2OMcYjKa4Dg3vE+bX8ty93EBnAUPX3gFsTkOav3U1FdT0zrHPamICTmZbAq/8rpLqugejI1l+XxZdRTF8APVv9yiYozMkpZEBCDKemJDgdijGmiclpidTUu1i544Bfzn/UOwgR+Q/uoa1xwHoRyQFqGt9X1Yv9EpEJGPl7D5G7/QD3nzfEOqeNCUATBnYjPExYVlBKpqdGU2s6VhPTH1v9aiaoZOcUEREmfHusf+u9GGNOTFx0JBMGdONwdb1fzn/UBKGqHzc+F28kB4UAABDmSURBVJEeuDunAXJUda9fojEBo6a+gTdXFnPO0B4kxXVwOhxjzFG8euNEv93h+zKK6UogB7gCuBL4n4jYRLkQ9991JRyoqmPGBCvrbUwg82fzry+jmH4OjG+8axCRJOB9YK7fojKOm5NTSJ+uHTnND+2axpjg4MsoprAmTUplPh5ngtSOskqWF5QxY3xfwvw0hd8YE/h8uYN4T0QWAnM8r68CFvgvJOO07NwiwgSuyLC5D8a0Z76sKHePiFyGeyY1wPOq+m//hmWcUtfg4o28YqYO6U7PLtFOh2OMcdCx5kGkAT1UdZmqvgW85dk+WURSVbWgrYI0beeDDXspPVxja04bY47Zl/AEUNHM9nLPeybE7K+s5bfvrKdvt46cMTjJ6XCMMQ47VoLooaprm270bBvgt4iMI+obXNw2ZyX7Dtfwl5ljiQi3cQjGtHfH+hY4Vv3Yjq0diHHWHxZuYll+Gb+fPtxvpYONMcHlWAkiT0RubLpRRH4ArPBfSKatzVu9i+eXbOU7p/a3kUvGmC8daxTTj4F/i8g1fJUQMoAo4FJ/B2baxvpdFdw7dzXjB8TziwuGOh2OMSaAHKsWUwmQKSJnAsM9m99V1Q/bJDLjdwcqa7npn3l07RjF09eMIyrC+h2MMV/xZU3qxar6lOfRouQgItNEZJOI5IvI/c28f7OIrBWRz0VkqYgM9Wy/xrOt8eESkdEtubY5tgaXcnv2KkrKa3jm2rFWkM8Y8w1++5NRRMKB2cB5wFBgZmMC8PKqqo5Q1dHAH4DHAFT1X6o62rP9OmCbqn7ur1jbo0cXbuKTLaX8dvowxvSLdzocY0wA8mebwgQgX1W3qmotkA1c4r2DqnrPs4jFvUBRUzM9x5pW8s6aXTz7cQHXTOzHVTYhzhhzFL7UYjpRfYAir9fFwMSmO4nILcBduDu/pzZznqtokli8jp0FzALo18++6HyxcU8F97yxhnH94/nVRcOcDscYE8Ac75VU1dmqmgrcB/zC+z0RmQhUqeoXRzn2eVXNUNWMpCSb+Xs85VV13PTKCuKiI3jmmrHWKW2MOSZ/fkPsBLwH1Sd7th1NNjC9ybYZfFVF1pyExk7pXQeP8My1Y+ne2QrxGWOOzZ8JIhdIF5GBIhKF+8t+nvcOIpLu9fICYIvXe2G4V7Cz/odW8NiiTXy8eR+/uXg44/p3czocY0wQ8FsfhKrWi8itwEIgHHhRVdeJyANAnqrOA24VkbOBOuAAcL3XKU4HilR1q79ibC8WrN3N7MUFzJzQl6snWl+NMcY3otrcwKHgk5GRoXl5eU6HEXA2lxxi+uxlDOoRx2s3TaJDRLjTIRljAoiIrFDVjObes17KEFZ+xN0pHRMVwbPXjrPkYIxpEUsQIcrlUu587XOK9lfxzLVjbXU4Y0yLWYIIUU+8v5kPN+7lVxcNZfwA65Q2xrScJYgQtHDdHp78MJ8rxiVz7aT+TodjjAlSliBCTP7eQ9z9+mpGJXfht9OHIyJOh2SMCVKWIEJIRXUds15ZQXRkGM9cO47oSOuUNsacOH/WYjJtyOVS7nptNYVlVfzrBxPp3dVWhTXGnBy7gwgRT32Yz/sbSvjFBacwMSXB6XCMMSHAEkQI+GBDCY+/v5nLxvbh+swBTodjjAkRliCCXMG+w/w4+3OG9+nMg5eOsE5pY0yrsQQRxA5V1zHr5TwiI8J47roM65Q2xrQq66QOUi6Xcvfrq9leVsUrN0ygj3VKG2Namd1BBKmnP8rnv+tL+Nn5p5CZmuh0OMaYEGQJIggt3riXPy3azPTRvfl+1gCnwzHGhChLEEFme2klt2ev4pSenXnospHWKW2M8RtLEEHkcE09s17JIzxMeO66cXSMsk5pY4z/WIIIEqrKPW+sJn/vYf4ycyx9u8U4HZIxJsRZgggSz3xcwIIv9nD/eUOYnG6d0sYY/7MEEQQ+2rSXRxdu4qJRvbnxtBSnwzHGtBOWIALcjrJKbp+zisE94njk2zZT2hjTdixBBLCq2npuemUFIsLz12UQE2XzGo0xbccSRIBSVe6du4bNJYd4auYY+iVYp7Qxpm1ZgghQzy/ZyjtrdnPPuUM4fVCS0+EYY9ohSxAB6JMt+3jkvY2cP6InN0+xTmljjDMsQQSYov1V3DZnFend43j08lHWKW2McYwliABypLaBWa+swOVSnrtuHLEdrFPaGOMc+wYKEKrK/W+tYeOeCl787ngGJMY6HZIxpp2zBBEANpcc4pEFG/lg417uOXcwZw7u7nRIxhhjCcJJuw4e4fFFm3lzZTGxHSK4/7wh3HS6dUobYwKDJQgHHKyq5ZmPCvj78u2gcMPkgfzojDTiY6OcDs0YY75kCaINVdc18NLy7Ty9OJ9DNfVcNiaZO89JJzneJsEZYwKPJYg2UN/g4q2VO3ls0Wb2VFQzdUh37p02mCE9OzsdmjHGHJUlCD9SVd7fsJc/vLeRLXsPM7pvV56YMZpJKQlOh2aMMcdlCcJP8rbv5+EFG8nbcYCUxFievXYs5w7raRPfjDFBw68JQkSmAX8GwoG/qerDTd6/GbgFaAAOA7NUdb3nvZHAc0BnwAWMV9Vqf8bbGraUHOKR9zbx/oYSusd14MFLR3BlRjIR4TYn0RgTXPyWIEQkHJgNnAMUA7kiMq8xAXi8qqrPeva/GHgMmCYiEcA/getUdbWIJAB1/oq1Newudw9ZnbuimNioCO45dzDfzxpo60YbY4KWP+8gJgD5qroVQESygUuALxOEqlZ47R8LqOf5t4A1qrras1+ZH+M8KeVVdTz9cT4vLduOKnw/ayC3nGlDVo0xwc+fCaIPUOT1uhiY2HQnEbkFuAuIAqZ6Ng8CVEQWAklAtqr+oZljZwGzAPr169eqwR9PdV0D/1i+ndmeIauXjunDXecMsiGrxpiQ4XgntarOBmaLyNXAL4Drccc1GRgPVAEfiMgKVf2gybHPA88DZGRkKG2gwaW8ubKYxxdtZnd5NWcOTuLeaUM4pZcNWTXGhBZ/JoidQF+v18mebUeTDTzjeV4MLFHVUgARmQ+MBT44yrF+p6p8sGEvf1i4kc0lhxnVtyuPXTmaU1NtyKoxJjT5M0HkAukiMhB3YpgBXO29g4ikq+oWz8sLgMbnC4F7RSQGqAWmAI/7MdZjWrHDPWQ1d7t7yOoz14xl2nAbsmqMCW1+SxCqWi8it+L+sg8HXlTVdSLyAJCnqvOAW0XkbNwjlA7gbl5CVQ+IyGO4k4wC81X1XX/FejRbSg7xh4WbWLS+hKS4Dvz+0uFcmdGXSBuyaoxpB0S1TZru/S4jI0Pz8vJa5Vy7y4/wxKItvLGiiJioCG6eksL3Jw8kJsrxLhtjjGlVnv7djObes288L+VVdTzzcQF/X7YNVfieZ8hqNxuyaoxphyxB4B6y+vKn25m9uICK6jouHd2HO88ZRN9uNmTVGNN+tfsEsbroID/85wp2lVdzxuAk7j13CEN725BVY4xp9wliQEIsqd078ccrR5GZmuh0OMYYEzDafYLoEhPJKzd8Y4K3Mca0ezZe0xhjTLMsQRhjjGmWJQhjjDHNsgRhjDGmWZYgjDHGNMsShDHGmGZZgjDGGNMsSxDGGGOaFTLVXEVkH7DjJE6RCJS2UjjBzj6Lr7PP4yv2WXxdKHwe/VU1qbk3QiZBnCwRyTtaydv2xj6Lr7PP4yv2WXxdqH8e1sRkjDGmWZYgjDHGNMsSxFeedzqAAGKfxdfZ5/EV+yy+LqQ/D+uDMMYY0yy7gzDGGNMsSxDGGGOa1a4ThIj0FZHFIrJeRNaJyB1Ox+Q0EQkXkVUi8o7TsThNRLqKyFwR2SgiG0TkVKdjcpKI3On5/+QLEZkjItFOx9SWRORFEdkrIl94besmIotEZIvnZ7yTMba2dp0ggHrgblUdCkwCbhGRoQ7H5LQ7gA1OBxEg/gy8p6pDgFG0489FRPoAtwMZqjocCAdmOBtVm3sJmNZk2/3AB6qaDnzgeR0y2nWCUNXdqrrS8/wQ7i+APs5G5RwRSQYuAP7mdCxOE5EuwOnACwCqWquqB52NynERQEcRiQBigF0Ox9OmVHUJsL/J5kuAf3ie/wOY3qZB+Vm7ThDeRGQAMAb4n7OROOoJ4F7A5XQgAWAgsA/4u6fJ7W8iEut0UE5R1Z3AH4FCYDdQrqr/dTaqgNBDVXd7nu8BejgZTGuzBAGISCfgTeDHqlrhdDxOEJELgb2qusLpWAJEBDAWeEZVxwCVhFjzQUt42tYvwZ04ewOxInKts1EFFnXPGQipeQPtPkGISCTu5PAvVX3L6XgclAVcLCLbgWxgqoj809mQHFUMFKtq4x3lXNwJo706G9imqvtUtQ54C8h0OKZAUCIivQA8P/c6HE+ratcJQkQEdxvzBlV9zOl4nKSqP1XVZFUdgLvz8UNVbbd/IarqHqBIRAZ7Np0FrHcwJKcVApNEJMbz/81ZtONOey/zgOs9z68H3nYwllbXrhME7r+ar8P91/Lnnsf5TgdlAsZtwL9EZA0wGnjQ4Xgc47mTmgusBNbi/u4I6TITTYnIHOBTYLCIFIvIDcDDwDkisgX3XdbDTsbY2qzUhjHGmGa19zsIY4wxR2EJwhhjTLMsQRhjjGmWJQhjjDHNsgRhjDGmWZYgTFATERWRP3m9/omI/LqVzv2SiFzeGuc6znWu8FSLXey1bYTX0Ov9IrLN8/z9Fp77ARE5u/WjNu1BhNMBGHOSaoDLROQhVS11OphGIhKhqvU+7n4DcKOqLm3coKprcc+9QEReAt5R1bktjUNVf9nSY4xpZHcQJtjV456wdWfTN5reAYjIYc/PM0TkYxF5W0S2isjDInKNiOSIyFoRSfU6zdkikicimz31qhrXzHhURHJFZI2I3OR13k9EZB7NzLoWkZme838hIo94tv0SmAy8ICKPHu+Xbe4cjb+biDzuWa/hAxFJavoZiMh4EVkuIqs9v2uciAzzPP/c87ukH/8jN+2FJQgTCmYD13hKdPtqFHAzcAru2fSDVHUC7lLnt3ntNwCYgLsM+rOeRXJuwF3NdDwwHrhRRAZ69h8L3KGqg7wvJiK9gUeAqbjvDMaLyHRVfQDIA65R1XuOFfDRzuF5OxbIU9VhwMfAr5ocGwW85oltFO5Zv0c8n8GfVXU0kIG7BpUxgCUIEwI8FXhfxr2gja9yPeuB1AAFQGPp6rW4k0Kj11XVpapbgK3AEOBbwHdE5HPc5eETgMa/vHNUdVsz1xsPfOQpdlcP/Av3ehMtcaxzuHAnAIB/4r4r8TYY2K2queD+zDzn+BT4mYjcB/RX1SMtjMmEMEsQJlQ8gfsve+81G+rx/BsXkTAgyuu9Gq/nLq/XLr7eN9e0Fo0CAtymqqM9j4FeayNUntRv0Xp8qqGjqq8CF+O+m5gvIlP9GpUJKpYgTEhQ1f3A67iTRKPtwDjP84uByBM49RUiEubpl0gBNgELgR96SsUjIoN8WEwoB5giIokiEg7MxN0U1BLHOkcY0NjfcjWwtMmxm4BeIjLeE3OciESISAqwVVWfxF2JdGQLYzIhzEYxmVDyJ+BWr9d/Bd4WkdXAe5zYX/eFuL+YOwM3q2q1iPwNdzPUSk/p630cZ6lJVd0tIvcDi3Hfgbyrqi0qDX2cc1QCE0TkF7jXJLiqybG1InIV8JSIdMR9x3A2cCVwnYjU4V4Rrd1WrDXfZNVcjQkBInJYVTs5HYcJLdbEZIwxpll2B2GMMaZZdgdhjDGmWZYgjDHGNMsShDHGmGZZgjDGGNMsSxDGGGOa9f8BI8zHXh3zMYcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM-MUxDJaT83",
        "outputId": "ba82fcb9-fe92-4a38-8e09-e788a1c0dbb4"
      },
      "source": [
        "# LSA Model\n",
        "number_of_topics=6\n",
        "words=10\n",
        "model=create_gensim_lsa_model(Clean_data,number_of_topics,words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, '0.779*\"datum\" + 0.210*\"use\" + 0.208*\"science\" + 0.164*\"big\" + 0.157*\"social\" + 0.154*\"mining\" + 0.124*\"analytic\" + 0.111*\"model\" + 0.109*\"network\" + 0.105*\"special\"'), (1, '-0.456*\"use\" + -0.291*\"base\" + -0.272*\"feature\" + 0.247*\"datum\" + -0.223*\"detection\" + -0.216*\"outlier\" + -0.198*\"network\" + -0.194*\"model\" + 0.150*\"science\" + 0.128*\"big\"'), (2, '-0.478*\"base\" + -0.338*\"feature\" + 0.295*\"use\" + 0.277*\"model\" + 0.222*\"outlier\" + 0.186*\"detection\" + -0.156*\"algorithm\" + -0.140*\"selection\" + 0.138*\"optimization\" + -0.124*\"approach\"'), (3, '0.737*\"model\" + -0.250*\"outlier\" + -0.236*\"detection\" + -0.153*\"use\" + 0.127*\"classification\" + 0.124*\"multi\" + -0.123*\"tree\" + 0.120*\"analysis\" + -0.102*\"automatic\" + -0.097*\"ensemble\"'), (4, '-0.404*\"network\" + 0.281*\"base\" + 0.278*\"detection\" + 0.268*\"outlier\" + -0.257*\"use\" + -0.175*\"feature\" + -0.153*\"neural\" + 0.138*\"tree\" + 0.136*\"model\" + 0.131*\"automatic\"'), (5, '0.384*\"feature\" + 0.316*\"classification\" + -0.268*\"approach\" + 0.202*\"exploit\" + -0.194*\"base\" + -0.185*\"network\" + 0.161*\"detection\" + 0.157*\"segmentation\" + 0.153*\"heartbeat\" + 0.153*\"simultaneous\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imvB__OuciJm"
      },
      "source": [
        "dictionary,doc_term_matrix= prepare_corpus(Clean_data)\n",
        "model_list_lsa,coherence_values_lsa = compute_coherence_values(dictionary,doc_term_matrix,Clean_data,40,2,6)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0KIt6Ruc3g7",
        "outputId": "16e4d310-da7e-44e2-94d9-f83da9644795"
      },
      "source": [
        "x = range(start, stop, step)\n",
        "for m, cv in zip(x, coherence_values_lsa):\n",
        "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num Topics = 2  has Coherence Value of 0.4254\n",
            "Num Topics = 3  has Coherence Value of 0.4002\n",
            "Num Topics = 4  has Coherence Value of 0.3941\n",
            "Num Topics = 5  has Coherence Value of 0.3736\n",
            "Num Topics = 6  has Coherence Value of 0.3877\n",
            "Num Topics = 7  has Coherence Value of 0.4098\n",
            "Num Topics = 8  has Coherence Value of 0.4305\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfyIz-gUMHRr"
      },
      "source": [
        "## (3) (4 points) Compare the results generated by the two topic modeling algorithms, which one is better? You should explain the reasons in details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wnr2itUHMHRr"
      },
      "source": [
        "# Write your answer here (no code needed for this question)\n",
        "\n",
        "'''\n",
        "LDA(Latent Dirichlet Allocation):\n",
        "LDA is one of the most popular topic modelling method. It classifies text into relevant topics.By finding the probability of finding a word in text and comparing it\n",
        "to probability of finding in relevant topic and then it allocates the topic . Using Gensim's LDA we can see that the optimal number of topics are 18 and\n",
        "coherence score obtained by applying LDA method is 0.77.\n",
        "\n",
        "\n",
        "LSA (Latent Semantic Analysis)\n",
        "Another Key model in topic modelling . It determines the topics by converting the text into single value equation by using SVD and then finds the cosine similarity to \n",
        "all the topics. The topics having the highest cosine similarity is allocated as the key topic. From the above observations , we can see that Coherence Value:0.42 and\n",
        "number of topics is 2.\n",
        "\n",
        "By Comparing both the scores we can see that we have higher coherence score for LDA than LSA. Since higher coherence score implies better alignment towards a topic,\n",
        "LDA fits the text best for topic modelling.\n",
        "\n",
        "\n",
        "'''\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}