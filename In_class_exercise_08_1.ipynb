{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In_class_exercise_08-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vamsikrishna1804/Vamsikrishnabharghava_INFO5731_Spring2021/blob/main/In_class_exercise_08_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJPwH-ZdE6KA"
      },
      "source": [
        "# **The eighth in-class-exercise (20 points in total, 3/30/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p52aker3E6KK"
      },
      "source": [
        "The data for this exercise is from the dataset you created from assignment three. Please perform answer the following questions based on your data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYeDY7shE6KL"
      },
      "source": [
        "## (1) (10 points) Write a python program to extract the sentiment related terms from the corpus. You may use python package such as polyglot or external lexicon resources in the question. Rank the sentiment related terms by frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "PJ8T9n0KE6KM",
        "outputId": "6b7d7a99-c8b4-4ef9-9e06-0547e49f1c48"
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv('assignment4file1.csv')\n",
        "df1=(df[['Document ID', 'Abstract', 'Sentiment']])\n",
        "df1"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document ID</th>\n",
              "      <th>Abstract</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Abstract not found       ...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>describe a method for st...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Scaling conditional rando...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>The paper addresses the i...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>In most natural language ...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>This paper presents a wor...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>Abstract—Natural Language...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>ABSTRACT: After twenty ye...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>Text statistics are frequ...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>We summarize our experien...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Document ID                                           Abstract Sentiment\n",
              "0             0                       Abstract not found       ...   Neutral\n",
              "1             1                        describe a method for st...  Positive\n",
              "2             2                       Scaling conditional rando...   Neutral\n",
              "3             3                       The paper addresses the i...   Neutral\n",
              "4             4                       In most natural language ...   Neutral\n",
              "..          ...                                                ...       ...\n",
              "95           95                       This paper presents a wor...  Positive\n",
              "96           96                       Abstract—Natural Language...  Negative\n",
              "97           97                       ABSTRACT: After twenty ye...  Positive\n",
              "98           98                       Text statistics are frequ...   Neutral\n",
              "99           99                       We summarize our experien...   Neutral\n",
              "\n",
              "[100 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrXEfwU4MgJb"
      },
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from textblob import Word\n",
        "import pandas as pd\n",
        "import nltk"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4umR6vQIM3Rk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "824db1b7-b285-41a1-f542-fdf6e9e3a3e0"
      },
      "source": [
        "df1['Special characters and Punctutation Removal'] = df1['Abstract'].str.replace('[,.~`\\?!@#$%^&\"*-/:;...()]','')\n",
        "print(df1)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Document ID  ...        Special characters and Punctutation Removal\n",
            "0             0  ...                       Abstract not found       ...\n",
            "1             1  ...                        describe a method for st...\n",
            "2             2  ...                       Scaling conditional rando...\n",
            "3             3  ...                       The paper addresses the i...\n",
            "4             4  ...                       In most natural language ...\n",
            "..          ...  ...                                                ...\n",
            "95           95  ...                       This paper presents a wor...\n",
            "96           96  ...                       Abstract—Natural Language...\n",
            "97           97  ...                       ABSTRACT After twenty yea...\n",
            "98           98  ...                       Text statistics are frequ...\n",
            "99           99  ...                       We summarize our experien...\n",
            "\n",
            "[100 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPIAUsHMNeQU",
        "outputId": "17414472-e106-4a61-efbd-dad22cd76822"
      },
      "source": [
        "df1['Removal of numbers'] = df1['Abstract'].str.replace('\\d+', '')\n",
        "print(df1)\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Document ID  ...                                 Removal of numbers\n",
            "0             0  ...                       Abstract not found       ...\n",
            "1             1  ...                        describe a method for st...\n",
            "2             2  ...                       Scaling conditional rando...\n",
            "3             3  ...                       The paper addresses the i...\n",
            "4             4  ...                       In most natural language ...\n",
            "..          ...  ...                                                ...\n",
            "95           95  ...                       This paper presents a wor...\n",
            "96           96  ...                       Abstract—Natural Language...\n",
            "97           97  ...                       ABSTRACT: After twenty ye...\n",
            "98           98  ...                       Text statistics are frequ...\n",
            "99           99  ...                       We summarize our experien...\n",
            "\n",
            "[100 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hK2MAkdNqAT",
        "outputId": "86446f2c-17f8-461d-e038-64dd3b0670b1"
      },
      "source": [
        "df1['Lower_case'] = df1['Abstract'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "print(df1)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Document ID  ...                                         Lower_case\n",
            "0             0  ...                                 abstract not found\n",
            "1             1  ...  describe a method for statistical modeling bas...\n",
            "2             2  ...  scaling conditional random fields for natural ...\n",
            "3             3  ...  the paper addresses the issue of cooperation b...\n",
            "4             4  ...  in most natural language processing applicatio...\n",
            "..          ...  ...                                                ...\n",
            "95           95  ...  this paper presents a workbench built by pribe...\n",
            "96           96  ...  abstract—natural language processing (nlp) is ...\n",
            "97           97  ...  abstract: after twenty years of disfavor, a te...\n",
            "98           98  ...  text statistics are frequently used in stylome...\n",
            "99           99  ...  we summarize our experience using framenet in ...\n",
            "\n",
            "[100 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 813
        },
        "id": "apruPW5MN4nS",
        "outputId": "dbe9330e-ee48-4e1f-f561-d14770c82ca8"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop=stopwords.words('english')\n",
        "df1['Removal of Stop words']=df1['Abstract'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "print(df1)\n",
        "df1\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "    Document ID  ...                              Removal of Stop words\n",
            "0             0  ...                                     Abstract found\n",
            "1             1  ...  describe method statistical modeling based max...\n",
            "2             2  ...  Scaling conditional random fields natural lang...\n",
            "3             3  ...  The paper addresses issue cooperation linguist...\n",
            "4             4  ...  In natural language processing applications, D...\n",
            "..          ...  ...                                                ...\n",
            "95           95  ...  This paper presents workbench built Priberam I...\n",
            "96           96  ...  Abstract—Natural Language Processing (NLP) eff...\n",
            "97           97  ...  ABSTRACT: After twenty years disfavor, technol...\n",
            "98           98  ...  Text statistics frequently used stylometry cry...\n",
            "99           99  ...  We summarize experience using FrameNet two rat...\n",
            "\n",
            "[100 rows x 7 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document ID</th>\n",
              "      <th>Abstract</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Special characters and Punctutation Removal</th>\n",
              "      <th>Removal of numbers</th>\n",
              "      <th>Lower_case</th>\n",
              "      <th>Removal of Stop words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Abstract not found       ...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Abstract not found       ...</td>\n",
              "      <td>Abstract not found       ...</td>\n",
              "      <td>abstract not found</td>\n",
              "      <td>Abstract found</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>describe a method for st...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>describe a method for st...</td>\n",
              "      <td>describe a method for st...</td>\n",
              "      <td>describe a method for statistical modeling bas...</td>\n",
              "      <td>describe method statistical modeling based max...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Scaling conditional rando...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Scaling conditional rando...</td>\n",
              "      <td>Scaling conditional rando...</td>\n",
              "      <td>scaling conditional random fields for natural ...</td>\n",
              "      <td>Scaling conditional random fields natural lang...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>The paper addresses the i...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>The paper addresses the i...</td>\n",
              "      <td>The paper addresses the i...</td>\n",
              "      <td>the paper addresses the issue of cooperation b...</td>\n",
              "      <td>The paper addresses issue cooperation linguist...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>In most natural language ...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>In most natural language ...</td>\n",
              "      <td>In most natural language ...</td>\n",
              "      <td>in most natural language processing applicatio...</td>\n",
              "      <td>In natural language processing applications, D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>This paper presents a wor...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>This paper presents a wor...</td>\n",
              "      <td>This paper presents a wor...</td>\n",
              "      <td>this paper presents a workbench built by pribe...</td>\n",
              "      <td>This paper presents workbench built Priberam I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>Abstract—Natural Language...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Abstract—Natural Language...</td>\n",
              "      <td>Abstract—Natural Language...</td>\n",
              "      <td>abstract—natural language processing (nlp) is ...</td>\n",
              "      <td>Abstract—Natural Language Processing (NLP) eff...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>ABSTRACT: After twenty ye...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>ABSTRACT After twenty yea...</td>\n",
              "      <td>ABSTRACT: After twenty ye...</td>\n",
              "      <td>abstract: after twenty years of disfavor, a te...</td>\n",
              "      <td>ABSTRACT: After twenty years disfavor, technol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>Text statistics are frequ...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Text statistics are frequ...</td>\n",
              "      <td>Text statistics are frequ...</td>\n",
              "      <td>text statistics are frequently used in stylome...</td>\n",
              "      <td>Text statistics frequently used stylometry cry...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>We summarize our experien...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>We summarize our experien...</td>\n",
              "      <td>We summarize our experien...</td>\n",
              "      <td>we summarize our experience using framenet in ...</td>\n",
              "      <td>We summarize experience using FrameNet two rat...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Document ID  ...                              Removal of Stop words\n",
              "0             0  ...                                     Abstract found\n",
              "1             1  ...  describe method statistical modeling based max...\n",
              "2             2  ...  Scaling conditional random fields natural lang...\n",
              "3             3  ...  The paper addresses issue cooperation linguist...\n",
              "4             4  ...  In natural language processing applications, D...\n",
              "..          ...  ...                                                ...\n",
              "95           95  ...  This paper presents workbench built Priberam I...\n",
              "96           96  ...  Abstract—Natural Language Processing (NLP) eff...\n",
              "97           97  ...  ABSTRACT: After twenty years disfavor, technol...\n",
              "98           98  ...  Text statistics frequently used stylometry cry...\n",
              "99           99  ...  We summarize experience using FrameNet two rat...\n",
              "\n",
              "[100 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ImUF2P2OJFo",
        "outputId": "51fb9524-6d97-43fd-aec5-8f614700052c"
      },
      "source": [
        "from textblob import TextBlob\n",
        "text_words = []\n",
        "emotional_words = []\n",
        "for i in df1['Removal of Stop words']:\n",
        "  text_words.append(i.split(' '))\n",
        "for i in text_words:\n",
        "  for j in i:\n",
        "    if TextBlob(j).sentiment.polarity != 0:\n",
        "      emotional_words.append(j)\n",
        "print(emotional_words)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['natural', 'random', 'natural', 'natural', 'general,', 'particular.', 'natural', 'base', 'natural', 'More', 'natural', 'Natural', 'subject', 'Natural', 'broad', 'narrow', 'broad', 'natural', 'natural', 'natural', 'Natural', 'unprocessed', 'Natural', 'natural', 'Natural', 'able', 'Natural', 'natural', 'natural', 'natural', 'linguistic', 'directly', 'appropriate', 'natural', 'better', 'vague', 'precise', 'natural', 'Natural', 'natural', 'significant', 'important', 'cultural', 'linguistic', 'direct', 'detailed', 'natural', 'high', 'interesting', 'new', 'natural', 'natural', 'naturally,', 'natural', 'modern', 'limited', 'behind', 'limited', 'intelligent', 'natural', 'military', 'natural', 'developed', 'base.', 'high', 'significant', 'far,', 'particular', 'much', 'particular', 'Natural', 'main', 'Natural', 'naturally', 'linguistic', 'Natural', 'large', 'natural', 'Contemporary', 'natural', 'natural', 'new', 'relevant', 'developed', 'natural', 'natural', 'broad', 'typical', 'good', 'linguistic', 'Natural', 'important', 'first', 'natural', 'natural', 'better', 'natural', 'creative,', 'Many', 'complex', 'becoming', 'past', 'high', 'whole', 'whole', 'Many', 'relevant', 'exact', 'general', 'special', 'subject', 'first', 'relevant', 'original', 'distinctly', 'developed', 'new', 'linguistic', 'natural', 'natural', 'Natural', 'little', 'early', 'natural', 'intelligent', 'natural', 'successful', 'natural', 'natural', 'Natural', 'Natural', 'Empirically', 'natural', 'sophisticated', 'natural', 'important', 'Many', 'Natural', 'usually', 'significant', 'natural', 'natural', 'effectively', 'other,', 'natural', 'effectively', 'other,', 'natural', 'natural', 'natural', 'linguistic', 'natural', 'natural', 'effective', 'natural', 'Natural', 'first', 'natural', 'mainly', 'new', 'natural', 'natural', 'typically', 'Natural', 'large', 'artificial', 'many', 'foreign', 'extremely', 'popular', 'natural', 'due', 'powerful', 'Unfortunately,', 'good', 'fit', 'much', 'special', 'natural', 'single', 'particular', 'Natural', 'effective', 'limited', 'particular', 'typically', 'easily', 'Natural', 'single', 'developed', 'advanced', 'natural', 'natural', 'new', 'Natural', 'Natural', 'wide', 'Natural', 'Natural', 'artificial', 'Natural', 'wide', 'Most', 'unable', 'Natural', 'Natural', 'Previous', 'approximate', 'useful', 'wide', 'Natural', 'limited', 'far', 'natural', 'natural', 'able', 'single', 'new', 'stereotypical', 'Natural', 'available', 'effectively', 'usefully', 'common', 'common', 'natural', 'widely', 'powerful', 'many', 'natural', 'tedious', 'sophisticated', 'natural', 'significantly', 'general', 'past', 'natural', 'natural', 'linguistic', 'considerable', 'effective', 'educational', 'natural', 'educational', 'effective', 'Natural', 'frequently', 'developed', 'natural', 'natural']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "nxTnQm9HOlAi",
        "outputId": "78f96b61-470f-4897-8ae2-c86a0e6899c1"
      },
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "emotional_wordcount = Counter(emotional_words)\n",
        "df_words = pd.DataFrame(list(zip(list (emotional_wordcount.keys()),list (emotional_wordcount.values()))), columns = ['words', 'Frequency'])\n",
        "df_words = df_words.sort_values(by=['Frequency'], ascending=False)\n",
        "df_words.insert(0, \"Rank\", np.arange(1,len(df_words)+1), True)\n",
        "df_words"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rank</th>\n",
              "      <th>words</th>\n",
              "      <th>Frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>natural</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2</td>\n",
              "      <td>Natural</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>3</td>\n",
              "      <td>linguistic</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>4</td>\n",
              "      <td>new</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>5</td>\n",
              "      <td>developed</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>92</td>\n",
              "      <td>naturally</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>93</td>\n",
              "      <td>main</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>94</td>\n",
              "      <td>far,</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>95</td>\n",
              "      <td>base.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>96</td>\n",
              "      <td>frequently</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>96 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Rank       words  Frequency\n",
              "0      1     natural         64\n",
              "6      2     Natural         29\n",
              "12     3  linguistic          7\n",
              "25     4         new          6\n",
              "32     5   developed          5\n",
              "..   ...         ...        ...\n",
              "38    92   naturally          1\n",
              "37    93        main          1\n",
              "34    94        far,          1\n",
              "33    95       base.          1\n",
              "95    96  frequently          1\n",
              "\n",
              "[96 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77R8yLD63sh4",
        "outputId": "8ea42edc-e40f-4b5e-d989-c0b597a8d031"
      },
      "source": [
        "\n",
        "Actual_positive = 0\n",
        "Actual_negative = 0\n",
        "Actual_neutral = 0\n",
        "for i in df['Sentiment']:\n",
        "  if i == 'Positive':\n",
        "    Actual_positive += 1\n",
        "  elif i == 'Negative':\n",
        "    Actual_negative += 1\n",
        "  elif i == 'Neutral':\n",
        "    Actual_neutral += 1\n",
        "print('Actual_positive = ', Actual_positive)\n",
        "print('Actual_negative = ', Actual_negative)\n",
        "print('Actual_neutral = ', Actual_neutral)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual_positive =  43\n",
            "Actual_negative =  14\n",
            "Actual_neutral =  43\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8Jdm1lbE6KN"
      },
      "source": [
        "## (2) (10 points) Compare the performance of the following tools in sentiment identification: TextBlob (https://textblob.readthedocs.io/en/dev/), VADER (https://github.com/cjhutto/vaderSentiment), TFIDF-based Support Vector Machine (SVM) (Split your data into training and testing data). Take your own annotation as the standard answers. \n",
        "\n",
        "Reference code: https://towardsdatascience.com/fine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mG8SMRtN2SF3",
        "outputId": "f779edd0-09fe-47c7-b731-0143f23aca76"
      },
      "source": [
        "from textblob import TextBlob\n",
        "positive = 0\n",
        "negative = 0\n",
        "neutral = 0\n",
        "for i in df['Abstract']:\n",
        "  sent = TextBlob(i)\n",
        "  if sent.sentiment.polarity > 0:\n",
        "    positive += 1\n",
        "  elif sent.sentiment.polarity < 0:\n",
        "    negative += 1\n",
        "  elif sent.sentiment.polarity == 0:\n",
        "    neutral += 1\n",
        "print('---------Using TextBlob model-------------')\n",
        "print(\"Positive = \", positive)\n",
        "print(\"Negative = \", negative)\n",
        "print(\"Neutral = \", neutral)\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "positive = 0\n",
        "negative = 0\n",
        "neutral = 0\n",
        "sentimental_analyzer = SentimentIntensityAnalyzer()\n",
        "for i in df['Abstract']:\n",
        "  sent = TextBlob(i)\n",
        "  if sentimental_analyzer.polarity_scores(i)['compound'] > 0:\n",
        "    positive += 1\n",
        "  elif sentimental_analyzer.polarity_scores(i)['compound'] < 0:\n",
        "    negative += 1\n",
        "  elif sentimental_analyzer.polarity_scores(i)['compound'] == 0:\n",
        "    neutral += 1\n",
        "print('----------Using Vader model----------------')\n",
        "print(\"Positive = \", positive)\n",
        "print(\"Negative = \", negative)\n",
        "print(\"Neutral = \", neutral)\n",
        "\n",
        "train=df[:80]\n",
        "test=df[80:]\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Create feature vectors\n",
        "vectorizer = TfidfVectorizer(min_df = 5,\n",
        "                             max_df = 0.8,\n",
        "                             sublinear_tf = True,\n",
        "                             use_idf = True)\n",
        "train_vectors = vectorizer.fit_transform(train['Abstract'])\n",
        "test_vectors = vectorizer.transform(test['Abstract'])\n",
        "import time\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "classifier_linear = svm.SVC(kernel='linear')\n",
        "t0 = time.time()\n",
        "classifier_linear.fit(train_vectors, train['Sentiment'])\n",
        "t1 = time.time()\n",
        "prediction_linear = classifier_linear.predict(test_vectors)\n",
        "t2 = time.time()\n",
        "time_linear_train = t1-t0\n",
        "time_linear_predict = t2-t1\n",
        "# results\n",
        "print(\"Training time: %fs; Prediction time: %fs\" % (time_linear_train, time_linear_predict))\n",
        "report = classification_report(test['Sentiment'], prediction_linear, output_dict=True)\n",
        "print('----------Using SVM----------------')\n",
        "print('Positive: ', report['Positive'])\n",
        "print('Negative: ', report['Negative'])\n",
        "print(\"Neutral:\", report['Neutral'])"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------Using TextBlob model-------------\n",
            "Positive =  75\n",
            "Negative =  9\n",
            "Neutral =  16\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "----------Using Vader model----------------\n",
            "Positive =  76\n",
            "Negative =  9\n",
            "Neutral =  15\n",
            "Training time: 0.003499s; Prediction time: 0.000510s\n",
            "----------Using SVM----------------\n",
            "Positive:  {'precision': 0.46153846153846156, 'recall': 0.75, 'f1-score': 0.5714285714285714, 'support': 8}\n",
            "Negative:  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}\n",
            "Neutral: {'precision': 0.7142857142857143, 'recall': 0.5, 'f1-score': 0.588235294117647, 'support': 10}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "id": "Fqm09lIY8pDn",
        "outputId": "69e3557c-8343-463e-f830-a47316a3e564"
      },
      "source": [
        "'''\n",
        "From the above models:\n",
        "Text Blob: In this sentiment analysis, we got 75 positives, 9 Negatives and 16 as Neutral.\n",
        "\n",
        "Vader: Using vader model, we got 76 positives, 9 negatives and 15 as Neutral.\n",
        "\n",
        "SVM: Using SVM model, we got precision for positives are 0.46.\n",
        "\n",
        "From the above three models, SVM model is most accurate and it is nearer to the original values.\n",
        "'''"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nFrom the above models:\\nText Blob: In this sentiment analysis, we got 75 positives, 9 Negatives and 16 as Neutral.\\n\\nVader: Using vader model, we got 76 positives, 9 negatives and 15 as Neutral.\\n\\nSVM: Using SVM model, we got precision for positives are 0.46.\\n\\nFrom the above three models, SVM model is most accurate and it is nearer to the original values.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    }
  ]
}